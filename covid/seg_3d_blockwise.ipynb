{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 0.1.0+460.g82a7933\n",
      "Python version: 3.7.4 (default, Jul 18 2019, 19:34:02)  [GCC 5.4.0]\n",
      "Numpy version: 1.18.1\n",
      "Pytorch version: 1.5.0\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.3.0\n",
      "Nibabel version: 3.1.0\n",
      "scikit-image version: 0.14.2\n",
      "Pillow version: 7.0.0\n",
      "Tensorboard version: 2.1.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "import shutil\n",
    "from glob import glob\n",
    "import logging\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import monai\n",
    "from monai.data import NiftiDataset, create_test_image_3d\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.metrics import compute_meandice\n",
    "from monai.visualize.img2tensorboard import plot_2d_or_3d_image\n",
    "from monai.transforms import \\\n",
    "    Compose, AddChannel, LoadNifti, \\\n",
    "    ScaleIntensity, RandSpatialCrop, \\\n",
    "    ToTensor, CastToType, SpatialPad\n",
    "\n",
    "monai.config.print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/marafath/scratch/eu_data'\n",
    "import matplotlib.pyplot as plt\n",
    "eu_labels = []\n",
    "\n",
    "for case in os.listdir(data_dir):\n",
    "    img = nib.load(os.path.join(data_dir,case,'image.nii.gz'))\n",
    "    img = img.get_fdata()\n",
    "    seg = nib.load(os.path.join(data_dir,case,'segmentation.nii.gz'))\n",
    "    seg = seg.get_fdata()\n",
    "    seg[seg > 6] = 1\n",
    "    \n",
    "    if np.max(seg) == 6:\n",
    "        eu_labels.append(1)\n",
    "    else:\n",
    "        eu_labels.append(0)\n",
    "        \n",
    "    seg[seg > 0] = 1\n",
    "    img_masked = np.multiply(img, seg)\n",
    "\n",
    "    '''\n",
    "    plt.figure('check', (18, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title('image')\n",
    "    plt.imshow(img_masked[:, :, 50], cmap='gray')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title('label')\n",
    "    plt.imshow(seg[:, :, 50])\n",
    "    plt.show()\n",
    "    '''\n",
    "    \n",
    "    img_masked = nib.Nifti1Image(img_masked, np.eye(4))\n",
    "    nib.save(img_masked,os.path.join(data_dir,case,'image_masked.nii.gz')) \n",
    "\n",
    "labels = np.asarray(eu_labels,np.int64)  \n",
    "np.save('eu_labels.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n",
      "52\n"
     ]
    }
   ],
   "source": [
    "print(len(labels))\n",
    "print(np.sum(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 1 0 1 1 1 0 1 1 1 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 1 0 1 0 1 1 1 0 1\n",
      " 0 0 0 1 1 1 1 1 0 1 0 0 0 0 1 0 1 0 0 1 0 1 1 1 1 0 0 1 1 1 0 1 1 0 1 0 0\n",
      " 1 1 1 0 0 1 1 1 0 0 0 0 1 0 1 1 0 0 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/marafath/scratch/eu_data'\n",
    "\n",
    "covid = 0\n",
    "noncovid = 0\n",
    "for case in os.listdir(data_dir):\n",
    "    s = nib.load(os.path.join(data_dir,case,'segmentation.nii.gz'))\n",
    "    s = s.get_fdata()\n",
    "    if np.max(s) == 6.0:\n",
    "        covid += 1\n",
    "    else:\n",
    "        noncovid += 1\n",
    "\n",
    "print('Covid: {}'.format(covid))\n",
    "print('nonCovid: {}'.format(noncovid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/marafath/scratch/eu_data'\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "for case in os.listdir(data_dir):\n",
    "    seg = nib.load(os.path.join(data_dir,case,'segmentation.nii.gz'))\n",
    "    seg = seg.get_fdata()\n",
    "    seg[seg == 6] = 0\n",
    "    # img = seg\n",
    "    # img = img - 100.5440 # Subtracting Mean\n",
    "\n",
    "    '''\n",
    "    plt.figure('check', (18, 6))\n",
    "    plt.title('Image')\n",
    "    plt.imshow(img[:, :, 50], cmap='gray')\n",
    "    print(np.max(img))\n",
    "    print(np.min(img))\n",
    "    plt.show()\n",
    "    '''\n",
    "    \n",
    "    seg = nib.Nifti1Image(seg, np.eye(4))\n",
    "    nib.save(seg,os.path.join(data_dir,case,'segmentation_no_infection.nii.gz')) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supervised learning data for training and validation\n",
    "data_dir = '/home/marafath/scratch/iran_organized_data/test'\n",
    "\n",
    "test_images = []\n",
    "test_labels = []\n",
    "test_dir = []\n",
    "\n",
    "for patient in os.listdir(data_dir):\n",
    "    for series in os.listdir(os.path.join(data_dir,patient)):\n",
    "        test_images.append(os.path.join(data_dir,patient,series,'image.nii.gz'))\n",
    "        test_labels.append(os.path.join(data_dir,patient,series,'segmentation_lobes.nii.gz'))\n",
    "        test_dir.append(os.path.join(data_dir,patient,series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossentropyND(torch.nn.CrossEntropyLoss):\n",
    "    \"\"\"\n",
    "    Network has to have NO NONLINEARITY!\n",
    "    \"\"\"\n",
    "    def forward(self, inp, target):\n",
    "        target = target.long()\n",
    "        num_classes = inp.size()[1]\n",
    "\n",
    "        i0 = 1\n",
    "        i1 = 2\n",
    "\n",
    "        while i1 < len(inp.shape): # this is ugly but torch only allows to transpose two axes at once\n",
    "            inp = inp.transpose(i0, i1)\n",
    "            i0 += 1\n",
    "            i1 += 1\n",
    "\n",
    "        inp = inp.contiguous()\n",
    "        inp = inp.view(-1, num_classes)\n",
    "\n",
    "        target = target.view(-1,)\n",
    "\n",
    "        return super(CrossentropyND, self).forward(inp, target)\n",
    "    \n",
    "class SoftDiceLoss(nn.Module):\n",
    "    def __init__(self, apply_nonlin=None, batch_dice=False, do_bg=True, smooth=1.):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super(SoftDiceLoss, self).__init__()\n",
    "\n",
    "        self.do_bg = do_bg\n",
    "        self.batch_dice = batch_dice\n",
    "        self.apply_nonlin = apply_nonlin\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, x, y, loss_mask=None):\n",
    "        shp_x = x.shape\n",
    "\n",
    "        if self.batch_dice:\n",
    "            axes = [0] + list(range(2, len(shp_x)))\n",
    "        else:\n",
    "            axes = list(range(2, len(shp_x)))\n",
    "\n",
    "        if self.apply_nonlin is not None:\n",
    "            x = self.apply_nonlin(x)\n",
    "\n",
    "        tp, fp, fn, _ = get_tp_fp_fn_tn(x, y, axes, loss_mask, False)\n",
    "\n",
    "        nominator = 2 * tp + self.smooth\n",
    "        denominator = 2 * tp + fp + fn + self.smooth\n",
    "\n",
    "        dc = nominator / denominator\n",
    "\n",
    "        if not self.do_bg:\n",
    "            if self.batch_dice:\n",
    "                dc = dc[1:]\n",
    "            else:\n",
    "                dc = dc[:, 1:]\n",
    "        dc = dc.mean()\n",
    "\n",
    "        return -dc\n",
    "    \n",
    "def get_tp_fp_fn_tn(net_output, gt, axes=None, mask=None, square=False):\n",
    "    \"\"\"\n",
    "    net_output must be (b, c, x, y(, z)))\n",
    "    gt must be a label map (shape (b, 1, x, y(, z)) OR shape (b, x, y(, z))) or one hot encoding (b, c, x, y(, z))\n",
    "    if mask is provided it must have shape (b, 1, x, y(, z)))\n",
    "    :param net_output:\n",
    "    :param gt:\n",
    "    :param axes: can be (, ) = no summation\n",
    "    :param mask: mask must be 1 for valid pixels and 0 for invalid pixels\n",
    "    :param square: if True then fp, tp and fn will be squared before summation\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if axes is None:\n",
    "        axes = tuple(range(2, len(net_output.size())))\n",
    "\n",
    "    shp_x = net_output.shape\n",
    "    shp_y = gt.shape\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if len(shp_x) != len(shp_y):\n",
    "            gt = gt.view((shp_y[0], 1, *shp_y[1:]))\n",
    "\n",
    "        if all([i == j for i, j in zip(net_output.shape, gt.shape)]):\n",
    "            # if this is the case then gt is probably already a one hot encoding\n",
    "            y_onehot = gt\n",
    "        else:\n",
    "            gt = gt.long()\n",
    "            y_onehot = torch.zeros(shp_x)\n",
    "            if net_output.device.type == \"cuda\":\n",
    "                y_onehot = y_onehot.cuda(net_output.device.index)\n",
    "            y_onehot.scatter_(1, gt, 1)\n",
    "\n",
    "    tp = net_output * y_onehot\n",
    "    fp = net_output * (1 - y_onehot)\n",
    "    fn = (1 - net_output) * y_onehot\n",
    "    tn = (1 - net_output) * (1 - y_onehot)\n",
    "\n",
    "    if mask is not None:\n",
    "        tp = torch.stack(tuple(x_i * mask[:, 0] for x_i in torch.unbind(tp, dim=1)), dim=1)\n",
    "        fp = torch.stack(tuple(x_i * mask[:, 0] for x_i in torch.unbind(fp, dim=1)), dim=1)\n",
    "        fn = torch.stack(tuple(x_i * mask[:, 0] for x_i in torch.unbind(fn, dim=1)), dim=1)\n",
    "        tn = torch.stack(tuple(x_i * mask[:, 0] for x_i in torch.unbind(tn, dim=1)), dim=1)\n",
    "\n",
    "    if square:\n",
    "        tp = tp ** 2\n",
    "        fp = fp ** 2\n",
    "        fn = fn ** 2\n",
    "        tn = tn ** 2\n",
    "\n",
    "    if len(axes) > 0:\n",
    "        tp = sum_tensor(tp, axes, keepdim=False)\n",
    "        fp = sum_tensor(fp, axes, keepdim=False)\n",
    "        fn = sum_tensor(fn, axes, keepdim=False)\n",
    "        tn = sum_tensor(tn, axes, keepdim=False)\n",
    "\n",
    "    return tp, fp, fn, tn\n",
    "\n",
    "class DC_and_CE_loss(nn.Module):\n",
    "    def __init__(self, soft_dice_kwargs, ce_kwargs, aggregate=\"sum\", square_dice=False, weight_ce=1, weight_dice=1):\n",
    "        \"\"\"\n",
    "        CAREFUL. Weights for CE and Dice do not need to sum to one. You can set whatever you want.\n",
    "        :param soft_dice_kwargs:\n",
    "        :param ce_kwargs:\n",
    "        :param aggregate:\n",
    "        :param square_dice:\n",
    "        :param weight_ce:\n",
    "        :param weight_dice:\n",
    "        \"\"\"\n",
    "        super(DC_and_CE_loss, self).__init__()\n",
    "        self.weight_dice = weight_dice\n",
    "        self.weight_ce = weight_ce\n",
    "        self.aggregate = aggregate\n",
    "        self.ce = CrossentropyND(**ce_kwargs)\n",
    "        self.dc = SoftDiceLoss(apply_nonlin=softmax_helper, **soft_dice_kwargs)\n",
    "\n",
    "    def forward(self, net_output, target):\n",
    "        dc_loss = self.dc(net_output, target) if self.weight_dice != 0 else 0\n",
    "        ce_loss = self.ce(net_output, target) if self.weight_ce != 0 else 0\n",
    "        if self.aggregate == \"sum\":\n",
    "            result = self.weight_ce * ce_loss + self.weight_dice * dc_loss\n",
    "        else:\n",
    "            raise NotImplementedError(\"nah son\") # reserved for other stuff (later)\n",
    "        return result\n",
    "\n",
    "def softmax_helper(x):\n",
    "    rpt = [1 for _ in range(len(x.size()))]\n",
    "    rpt[1] = x.size(1)\n",
    "    x_max = x.max(1, keepdim=True)[0].repeat(*rpt)\n",
    "    e_x = torch.exp(x - x_max)\n",
    "    return e_x / e_x.sum(1, keepdim=True).repeat(*rpt)\n",
    "\n",
    "def sum_tensor(inp, axes, keepdim=False):\n",
    "    axes = np.unique(axes).astype(int)\n",
    "    if keepdim:\n",
    "        for ax in axes:\n",
    "            inp = inp.sum(int(ax), keepdim=True)\n",
    "    else:\n",
    "        for ax in sorted(axes, reverse=True):\n",
    "            inp = inp.sum(int(ax))\n",
    "    return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/marafath/scratch/3d_seg_ct'\n",
    "train_images = []\n",
    "train_labels = []\n",
    "\n",
    "val_images = []\n",
    "val_labels = []\n",
    "\n",
    "for case in os.listdir(data_dir):\n",
    "    if case == \".ipynb_checkpoints\":\n",
    "        continue   \n",
    "    '''\n",
    "    if int(case[2:4]) < 65:\n",
    "        train_images.append(os.path.join(data_dir,case,'image.nii.gz'))\n",
    "        train_labels.append(os.path.join(data_dir,case,'label.nii.gz'))\n",
    "    else:\n",
    "        val_images.append(os.path.join(data_dir,case,'image.nii.gz'))\n",
    "        val_labels.append(os.path.join(data_dir,case,'label.nii.gz')) \n",
    "    '''    \n",
    "    if int(case[2:4]) < 17 or int(case[2:4]) > 32:\n",
    "        train_images.append(os.path.join(data_dir,case,'image.nii.gz'))\n",
    "        train_labels.append(os.path.join(data_dir,case,'label.nii.gz'))\n",
    "    else:\n",
    "        val_images.append(os.path.join(data_dir,case,'image.nii.gz'))\n",
    "        val_labels.append(os.path.join(data_dir,case,'label.nii.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/marafath/scratch/eu_data'\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for case in os.listdir(data_dir):\n",
    "    images.append(os.path.join(data_dir,case,'image.nii.gz'))\n",
    "    labels.append(os.path.join(data_dir,case,'segmentation.nii.gz'))\n",
    "\n",
    "val_images = images[:24]\n",
    "val_labels = labels[:24]\n",
    "\n",
    "train_images = images[24:]\n",
    "train_labels = labels[24:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imtrans = Compose([\n",
    "    ScaleIntensity(),\n",
    "    AddChannel(),\n",
    "    CastToType(), \n",
    "    RandSpatialCrop((96, 96, 96), random_size=False),\n",
    "    SpatialPad((96, 96, 96), mode='constant'),\n",
    "    ToTensor()\n",
    "])\n",
    "train_segtrans = Compose([\n",
    "    AddChannel(),\n",
    "    CastToType(), \n",
    "    RandSpatialCrop((96, 96, 96), random_size=False),\n",
    "    SpatialPad((96, 96, 96), mode='constant'),\n",
    "    ToTensor()\n",
    "])\n",
    "val_imtrans = Compose([\n",
    "    ScaleIntensity(),\n",
    "    AddChannel(),\n",
    "    CastToType(),\n",
    "    SpatialPad((96, 96, 96), mode='constant'),\n",
    "    ToTensor()\n",
    "])\n",
    "val_segtrans = Compose([\n",
    "    AddChannel(),\n",
    "    CastToType(),\n",
    "    SpatialPad((96, 96, 96), mode='constant'),\n",
    "    ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Transform\n",
    "test_imtrans = Compose([\n",
    "    ScaleIntensity(),\n",
    "    AddChannel(),\n",
    "    CastToType(),\n",
    "    SpatialPad((96, 96, 96), mode='constant'),\n",
    "    ToTensor()\n",
    "])\n",
    "test_segtrans = Compose([\n",
    "    AddChannel(),\n",
    "    CastToType(),\n",
    "    SpatialPad((96, 96, 96), mode='constant'),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "# create a validation data loader\n",
    "test_ds = NiftiDataset(test_images, test_labels, transform=test_imtrans, seg_transform=test_segtrans)\n",
    "test_loader = DataLoader(test_ds, batch_size=1, num_workers=4, pin_memory=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ds = NiftiDataset(val_images, val_labels, transform=val_imtrans, seg_transform=val_segtrans)\n",
    "loader = DataLoader(ds, batch_size=1, num_workers=2, pin_memory=torch.cuda.is_available())\n",
    "im, seg = monai.utils.misc.first(loader)\n",
    "im = np.squeeze(im)\n",
    "seg = np.squeeze(seg)\n",
    "print('image shape: {}, label shape: {}'.format(im.shape, seg.shape))\n",
    "sl = 54\n",
    "plt.figure('check', (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('image')\n",
    "plt.imshow(im[:, :, sl], cmap='gray')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('segmentation')\n",
    "plt.imshow(seg[:, :, sl])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a training data loader\n",
    "train_ds = NiftiDataset(train_images, train_labels, transform=train_imtrans, seg_transform=train_segtrans)\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=8, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "# create a validation data loader\n",
    "val_ds = NiftiDataset(val_images, val_labels, transform=val_imtrans, seg_transform=val_segtrans)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, num_workers=4, pin_memory=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining model and hyperparameters\n",
    "device = torch.device('cuda:0')\n",
    "model = monai.networks.nets.UNet(\n",
    "    dimensions=3,\n",
    "    in_channels=1,\n",
    "    out_channels=7,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2\n",
    ").to(device)\n",
    "\n",
    "loss_function = DC_and_CE_loss({'smooth': 1e-5, 'do_bg': False}, {})\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epc = 15\n",
    "val_interval = 1\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = list()\n",
    "metric_values = list()\n",
    "writer = SummaryWriter()\n",
    "for epoch in range(epc):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{epc}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for batch_data in train_loader:\n",
    "        step += 1\n",
    "        inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_len = len(train_ds) // train_loader.batch_size\n",
    "        print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n",
    "        writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            metric_sum = 0.0\n",
    "            metric_count = 0\n",
    "            val_images = None\n",
    "            val_labels = None\n",
    "            val_outputs = None\n",
    "            for val_data in val_loader:\n",
    "                val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
    "                roi_size = (160, 160, 160)\n",
    "                sw_batch_size = 4\n",
    "                val_outputs = sliding_window_inference(val_images, roi_size, sw_batch_size, model)\n",
    "                value = compute_meandice(y_pred=val_outputs, y=val_labels, include_background=False, \n",
    "                                         to_onehot_y=True, mutually_exclusive=True)\n",
    "                metric_count += len(value)\n",
    "                metric_sum += value.sum().item()\n",
    "                print(metric_sum)\n",
    "            print(metric_count)\n",
    "            metric = metric_sum / metric_count\n",
    "            metric_values.append(metric)\n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), '/home/marafath/scratch/saved_models/UNet3D_eu_best_metric_model.pth')\n",
    "                print(\"saved new best metric model\")\n",
    "            print(\n",
    "                \"current epoch: {} current mean dice: {:.4f} best mean dice: {:.4f} at epoch {}\".format(\n",
    "                    epoch + 1, metric, best_metric, best_metric_epoch\n",
    "                )\n",
    "            )\n",
    "            writer.add_scalar(\"val_mean_dice\", metric, epoch + 1)\n",
    "            # plot the last model output as GIF image in TensorBoard with the corresponding image and label\n",
    "            plot_2d_or_3d_image(val_images, epoch + 1, writer, index=0, tag=\"image\")\n",
    "            plot_2d_or_3d_image(val_labels, epoch + 1, writer, index=0, tag=\"label\")\n",
    "            plot_2d_or_3d_image(val_outputs, epoch + 1, writer, index=0, tag=\"output\")\n",
    "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "i = 0\n",
    "for val_data in test_loader:\n",
    "    im = val_data[0]\n",
    "    seg = val_data[1]\n",
    "\n",
    "    im = im.cpu().detach().numpy()\n",
    "    im = np.squeeze(im)\n",
    "\n",
    "    seg = seg.cpu().detach().numpy()\n",
    "    seg = np.squeeze(seg)\n",
    "    \n",
    "    sl = 50\n",
    "    plt.figure('check', (18, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title('image ' + str(i))\n",
    "    plt.imshow(im[:, :, sl], cmap='gray')\n",
    "    print(im.shape)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title('label ' + str(i))\n",
    "    plt.imshow(seg[:, :, sl])\n",
    "    print(seg.shape)\n",
    "    plt.show()\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
