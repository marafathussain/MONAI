{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 0.1.0+460.g82a7933.dirty\n",
      "Python version: 3.7.4 (default, Jul 18 2019, 19:34:02)  [GCC 5.4.0]\n",
      "Numpy version: 1.18.1\n",
      "Pytorch version: 1.5.0\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.3.0\n",
      "Nibabel version: 3.1.0\n",
      "scikit-image version: 0.14.2\n",
      "Pillow version: 7.0.0\n",
      "Tensorboard version: 2.1.0\n",
      "----------\n",
      "epoch 1/100\n",
      "1/406, train_loss: 0.4481\n",
      "2/406, train_loss: 4.3319\n",
      "3/406, train_loss: 2.5213\n",
      "4/406, train_loss: 1.2392\n",
      "5/406, train_loss: 1.4081\n",
      "6/406, train_loss: 0.1549\n",
      "7/406, train_loss: 2.3647\n",
      "8/406, train_loss: 1.5807\n",
      "9/406, train_loss: 0.6760\n",
      "10/406, train_loss: 1.6570\n",
      "11/406, train_loss: 0.2860\n",
      "12/406, train_loss: 0.2417\n",
      "13/406, train_loss: 2.3320\n",
      "14/406, train_loss: 0.6073\n",
      "15/406, train_loss: 1.3389\n",
      "16/406, train_loss: 0.7959\n",
      "17/406, train_loss: 0.6613\n",
      "18/406, train_loss: 0.6536\n",
      "19/406, train_loss: 0.6264\n",
      "20/406, train_loss: 0.6026\n",
      "21/406, train_loss: 1.2987\n",
      "22/406, train_loss: 0.4685\n",
      "23/406, train_loss: 0.9136\n",
      "24/406, train_loss: 0.4005\n",
      "25/406, train_loss: 1.5980\n",
      "26/406, train_loss: 0.9675\n",
      "27/406, train_loss: 0.6228\n",
      "28/406, train_loss: 0.4274\n",
      "29/406, train_loss: 0.9932\n",
      "30/406, train_loss: 0.8951\n",
      "31/406, train_loss: 0.5325\n",
      "32/406, train_loss: 0.5913\n",
      "33/406, train_loss: 0.7257\n",
      "34/406, train_loss: 0.5700\n",
      "35/406, train_loss: 0.6708\n",
      "36/406, train_loss: 0.5565\n",
      "37/406, train_loss: 1.1608\n",
      "38/406, train_loss: 0.6184\n",
      "39/406, train_loss: 0.3701\n",
      "40/406, train_loss: 0.1469\n",
      "41/406, train_loss: 0.3152\n",
      "42/406, train_loss: 0.4536\n",
      "43/406, train_loss: 0.2948\n",
      "44/406, train_loss: 2.2517\n",
      "45/406, train_loss: 0.2208\n",
      "46/406, train_loss: 0.7081\n",
      "47/406, train_loss: 1.3074\n",
      "48/406, train_loss: 1.4851\n",
      "49/406, train_loss: 0.9423\n",
      "50/406, train_loss: 1.3480\n",
      "51/406, train_loss: 1.6176\n",
      "52/406, train_loss: 0.1627\n",
      "53/406, train_loss: 0.1487\n",
      "54/406, train_loss: 0.8608\n",
      "55/406, train_loss: 1.1720\n",
      "56/406, train_loss: 0.8167\n",
      "57/406, train_loss: 0.7166\n",
      "58/406, train_loss: 1.4369\n",
      "59/406, train_loss: 1.0792\n",
      "60/406, train_loss: 1.0128\n",
      "61/406, train_loss: 0.7234\n",
      "62/406, train_loss: 0.4824\n",
      "63/406, train_loss: 0.3404\n",
      "64/406, train_loss: 0.7144\n",
      "65/406, train_loss: 1.9310\n",
      "66/406, train_loss: 0.2148\n",
      "67/406, train_loss: 0.1892\n",
      "68/406, train_loss: 1.9775\n",
      "69/406, train_loss: 0.5263\n",
      "70/406, train_loss: 2.3246\n",
      "71/406, train_loss: 2.4121\n",
      "72/406, train_loss: 0.2883\n",
      "73/406, train_loss: 1.6972\n",
      "74/406, train_loss: 0.9600\n",
      "75/406, train_loss: 1.0833\n",
      "76/406, train_loss: 0.6277\n",
      "77/406, train_loss: 0.7020\n",
      "78/406, train_loss: 1.2799\n",
      "79/406, train_loss: 0.7054\n",
      "80/406, train_loss: 0.4437\n",
      "81/406, train_loss: 1.3830\n",
      "82/406, train_loss: 0.3848\n",
      "83/406, train_loss: 1.2051\n",
      "84/406, train_loss: 1.4384\n",
      "85/406, train_loss: 0.4970\n",
      "86/406, train_loss: 0.5957\n",
      "87/406, train_loss: 0.7429\n",
      "88/406, train_loss: 0.6441\n",
      "89/406, train_loss: 0.7466\n",
      "90/406, train_loss: 0.6501\n",
      "91/406, train_loss: 0.6581\n",
      "92/406, train_loss: 0.6396\n",
      "93/406, train_loss: 0.8105\n",
      "94/406, train_loss: 0.7994\n",
      "95/406, train_loss: 0.7973\n",
      "96/406, train_loss: 0.6284\n",
      "97/406, train_loss: 0.7522\n",
      "98/406, train_loss: 0.6976\n",
      "99/406, train_loss: 0.6736\n",
      "100/406, train_loss: 0.6557\n",
      "101/406, train_loss: 0.9007\n",
      "102/406, train_loss: 0.5946\n",
      "103/406, train_loss: 0.9996\n",
      "104/406, train_loss: 0.9049\n",
      "105/406, train_loss: 0.5994\n",
      "106/406, train_loss: 0.6020\n",
      "107/406, train_loss: 0.5258\n",
      "108/406, train_loss: 0.5781\n",
      "109/406, train_loss: 0.8517\n",
      "110/406, train_loss: 0.4918\n",
      "111/406, train_loss: 0.6048\n",
      "112/406, train_loss: 0.4779\n",
      "113/406, train_loss: 0.7266\n",
      "114/406, train_loss: 0.8639\n",
      "115/406, train_loss: 0.9869\n",
      "116/406, train_loss: 1.0849\n",
      "117/406, train_loss: 0.6349\n",
      "118/406, train_loss: 0.8694\n",
      "119/406, train_loss: 0.8344\n",
      "120/406, train_loss: 0.5848\n",
      "121/406, train_loss: 0.6368\n",
      "122/406, train_loss: 0.6368\n",
      "123/406, train_loss: 0.6454\n",
      "124/406, train_loss: 0.6999\n",
      "125/406, train_loss: 0.6382\n",
      "126/406, train_loss: 0.6032\n",
      "127/406, train_loss: 0.8185\n",
      "128/406, train_loss: 0.6451\n",
      "129/406, train_loss: 0.7808\n",
      "130/406, train_loss: 0.5466\n",
      "131/406, train_loss: 0.7867\n",
      "132/406, train_loss: 0.7148\n",
      "133/406, train_loss: 0.4974\n",
      "134/406, train_loss: 0.5776\n",
      "135/406, train_loss: 0.7151\n",
      "136/406, train_loss: 0.6466\n",
      "137/406, train_loss: 0.6498\n",
      "138/406, train_loss: 0.5737\n",
      "139/406, train_loss: 0.9470\n",
      "140/406, train_loss: 0.5305\n",
      "141/406, train_loss: 0.3851\n",
      "142/406, train_loss: 0.4639\n",
      "143/406, train_loss: 1.2649\n",
      "144/406, train_loss: 1.2540\n",
      "145/406, train_loss: 1.0367\n",
      "146/406, train_loss: 0.5487\n",
      "147/406, train_loss: 0.4571\n",
      "148/406, train_loss: 0.9769\n",
      "149/406, train_loss: 0.6584\n",
      "150/406, train_loss: 0.5415\n",
      "151/406, train_loss: 0.5978\n",
      "152/406, train_loss: 0.5482\n",
      "153/406, train_loss: 0.7281\n",
      "154/406, train_loss: 0.4842\n",
      "155/406, train_loss: 1.0512\n",
      "156/406, train_loss: 1.0120\n",
      "157/406, train_loss: 0.8746\n",
      "158/406, train_loss: 0.9259\n",
      "159/406, train_loss: 0.5654\n",
      "160/406, train_loss: 0.6051\n",
      "161/406, train_loss: 0.6904\n",
      "162/406, train_loss: 0.6547\n",
      "163/406, train_loss: 0.6848\n",
      "164/406, train_loss: 0.6433\n",
      "165/406, train_loss: 0.7385\n",
      "166/406, train_loss: 0.6461\n",
      "167/406, train_loss: 0.6809\n",
      "168/406, train_loss: 0.8039\n",
      "169/406, train_loss: 0.6325\n",
      "170/406, train_loss: 0.6355\n",
      "171/406, train_loss: 0.5666\n",
      "172/406, train_loss: 0.6176\n",
      "173/406, train_loss: 0.5774\n",
      "174/406, train_loss: 0.5928\n",
      "175/406, train_loss: 0.8444\n",
      "176/406, train_loss: 0.5910\n",
      "177/406, train_loss: 0.5242\n",
      "178/406, train_loss: 0.8737\n",
      "179/406, train_loss: 0.8440\n",
      "180/406, train_loss: 0.6358\n",
      "181/406, train_loss: 0.5536\n",
      "182/406, train_loss: 0.5990\n",
      "183/406, train_loss: 0.6718\n",
      "184/406, train_loss: 0.8696\n",
      "185/406, train_loss: 0.8064\n",
      "186/406, train_loss: 0.8285\n",
      "187/406, train_loss: 0.7842\n",
      "188/406, train_loss: 0.7279\n",
      "189/406, train_loss: 0.4466\n",
      "190/406, train_loss: 0.6122\n",
      "191/406, train_loss: 1.1443\n",
      "192/406, train_loss: 0.5164\n",
      "193/406, train_loss: 0.3682\n",
      "194/406, train_loss: 1.4176\n",
      "195/406, train_loss: 0.4723\n",
      "196/406, train_loss: 1.2403\n",
      "197/406, train_loss: 0.3916\n",
      "198/406, train_loss: 0.8375\n",
      "199/406, train_loss: 1.2147\n",
      "200/406, train_loss: 0.4256\n",
      "201/406, train_loss: 0.6387\n",
      "202/406, train_loss: 1.0663\n",
      "203/406, train_loss: 0.8459\n",
      "204/406, train_loss: 0.5867\n",
      "205/406, train_loss: 0.5896\n",
      "206/406, train_loss: 0.6323\n",
      "207/406, train_loss: 0.6365\n",
      "208/406, train_loss: 0.8080\n",
      "209/406, train_loss: 0.7584\n",
      "210/406, train_loss: 0.6618\n",
      "211/406, train_loss: 0.7505\n",
      "212/406, train_loss: 0.6570\n",
      "213/406, train_loss: 0.6926\n",
      "214/406, train_loss: 0.6366\n",
      "215/406, train_loss: 0.6989\n",
      "216/406, train_loss: 0.6970\n",
      "217/406, train_loss: 0.6996\n",
      "218/406, train_loss: 0.6499\n",
      "219/406, train_loss: 0.6286\n",
      "220/406, train_loss: 0.7032\n",
      "221/406, train_loss: 0.6034\n",
      "222/406, train_loss: 0.7171\n",
      "223/406, train_loss: 0.7187\n",
      "224/406, train_loss: 0.8329\n",
      "225/406, train_loss: 0.7016\n",
      "226/406, train_loss: 0.6839\n",
      "227/406, train_loss: 0.6873\n",
      "228/406, train_loss: 0.7645\n",
      "229/406, train_loss: 0.6890\n",
      "230/406, train_loss: 0.6002\n",
      "231/406, train_loss: 0.6846\n",
      "232/406, train_loss: 0.6004\n",
      "233/406, train_loss: 0.7190\n",
      "234/406, train_loss: 0.7055\n",
      "235/406, train_loss: 0.7308\n",
      "236/406, train_loss: 0.7975\n",
      "237/406, train_loss: 0.5257\n",
      "238/406, train_loss: 0.5705\n",
      "239/406, train_loss: 0.8136\n",
      "240/406, train_loss: 0.7695\n",
      "241/406, train_loss: 0.5120\n",
      "242/406, train_loss: 0.5625\n",
      "243/406, train_loss: 0.8661\n",
      "244/406, train_loss: 0.6411\n",
      "245/406, train_loss: 0.5374\n",
      "246/406, train_loss: 0.5603\n",
      "247/406, train_loss: 0.7375\n",
      "248/406, train_loss: 0.6160\n",
      "249/406, train_loss: 0.5946\n",
      "250/406, train_loss: 0.5725\n",
      "251/406, train_loss: 0.9303\n",
      "252/406, train_loss: 0.4474\n",
      "253/406, train_loss: 0.8131\n",
      "254/406, train_loss: 1.1577\n",
      "255/406, train_loss: 0.9004\n",
      "256/406, train_loss: 0.6360\n",
      "257/406, train_loss: 0.6352\n",
      "258/406, train_loss: 0.6373\n",
      "259/406, train_loss: 0.6342\n",
      "260/406, train_loss: 0.8054\n",
      "261/406, train_loss: 0.7916\n",
      "262/406, train_loss: 0.6596\n",
      "263/406, train_loss: 0.6599\n",
      "264/406, train_loss: 0.6301\n",
      "265/406, train_loss: 0.6051\n",
      "266/406, train_loss: 0.8314\n",
      "267/406, train_loss: 0.6296\n",
      "268/406, train_loss: 0.7756\n",
      "269/406, train_loss: 0.8668\n",
      "270/406, train_loss: 0.6502\n",
      "271/406, train_loss: 0.5290\n",
      "272/406, train_loss: 0.5185\n",
      "273/406, train_loss: 0.6942\n",
      "274/406, train_loss: 0.6274\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import monai\n",
    "from monai.data import NiftiDataset\n",
    "from monai.transforms import Compose, CastToType, SpatialPad, AddChannel, ScaleIntensity, Resize, RandRotate, SpatialCrop, ToTensor\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ImHistNet(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 n_input_channels=1,\n",
    "                 n_bins = 64,\n",
    "                 n_classes=400):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv3d(n_input_channels,\n",
    "                               n_bins,\n",
    "                               kernel_size=1,\n",
    "                               stride=1,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(self.in_planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool3d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, block_inplanes[0], layers[0],\n",
    "                                       shortcut_type)\n",
    "        self.layer2 = self._make_layer(block,\n",
    "                                       block_inplanes[1],\n",
    "                                       layers[1],\n",
    "                                       shortcut_type,\n",
    "                                       stride=2)\n",
    "        self.layer3 = self._make_layer(block,\n",
    "                                       block_inplanes[2],\n",
    "                                       layers[2],\n",
    "                                       shortcut_type,\n",
    "                                       stride=2)\n",
    "        self.layer4 = self._make_layer(block,\n",
    "                                       block_inplanes[3],\n",
    "                                       layers[3],\n",
    "                                       shortcut_type,\n",
    "                                       stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
    "        self.fc = nn.Linear(block_inplanes[3] * block.expansion, n_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                nn.init.kaiming_normal_(m.weight,\n",
    "                                        mode='fan_out',\n",
    "                                        nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm3d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _downsample_basic_block(self, x, planes, stride):\n",
    "        out = F.avg_pool3d(x, kernel_size=1, stride=stride)\n",
    "        zero_pads = torch.zeros(out.size(0), planes - out.size(1), out.size(2),\n",
    "                                out.size(3), out.size(4))\n",
    "        if isinstance(out.data, torch.cuda.FloatTensor):\n",
    "            zero_pads = zero_pads.cuda()\n",
    "\n",
    "        out = torch.cat([out.data, zero_pads], dim=1)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, shortcut_type, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_planes != planes * block.expansion:\n",
    "            if shortcut_type == 'A':\n",
    "                downsample = partial(self._downsample_basic_block,\n",
    "                                     planes=planes * block.expansion,\n",
    "                                     stride=stride)\n",
    "            else:\n",
    "                downsample = nn.Sequential(\n",
    "                    conv1x1x1(self.in_planes, planes * block.expansion, stride),\n",
    "                    nn.BatchNorm3d(planes * block.expansion))\n",
    "\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(in_planes=self.in_planes,\n",
    "                  planes=planes,\n",
    "                  stride=stride,\n",
    "                  downsample=downsample))\n",
    "        self.in_planes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.in_planes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        if not self.no_max_pool:\n",
    "            x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def main():\n",
    "    monai.config.print_config()\n",
    "    logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "\n",
    "    # Training data paths\n",
    "    data_dir = '/home/marafath/scratch/iran_organized_data2'\n",
    "\n",
    "    covid_pat = 0\n",
    "    non_covid_pat = 0\n",
    "\n",
    "    images_p = []\n",
    "    labels_p = []\n",
    "    images_n = []\n",
    "    labels_n = []\n",
    "\n",
    "    for patient in os.listdir(data_dir):\n",
    "        if int(patient[-1]) == 0 and non_covid_pat > 236:\n",
    "            continue \n",
    "\n",
    "        if int(patient[-1]) == 1:\n",
    "            covid_pat += 1\n",
    "            for series in os.listdir(os.path.join(data_dir,patient)):\n",
    "                labels_p.append(1)\n",
    "                images_p.append(os.path.join(data_dir,patient,series,'masked_infection.nii.gz'))\n",
    "        else:\n",
    "            non_covid_pat += 1\n",
    "            for series in os.listdir(os.path.join(data_dir,patient)):\n",
    "                labels_n.append(0)\n",
    "                images_n.append(os.path.join(data_dir,patient,series,'masked_infection.nii.gz'))\n",
    "            \n",
    "    train_images = []\n",
    "    train_labels = []\n",
    "\n",
    "    val_images = []\n",
    "    val_labels = []\n",
    "\n",
    "    for i in range(0,len(images_p)):\n",
    "        if i < 407:\n",
    "            train_images.append(images_p[i])\n",
    "            train_labels.append(labels_p[i])\n",
    "        else:\n",
    "            val_images.append(images_p[i])\n",
    "            val_labels.append(labels_p[i])\n",
    "\n",
    "    for i in range(0,len(images_n)):\n",
    "        if i < 405:\n",
    "            train_images.append(images_n[i])\n",
    "            train_labels.append(labels_n[i])\n",
    "        else:\n",
    "            val_images.append(images_n[i])\n",
    "            val_labels.append(labels_n[i])  \n",
    "    \n",
    "    train_labels = np.asarray(train_labels,np.int64)\n",
    "    val_labels = np.asarray(val_labels,np.int64)\n",
    "\n",
    "\n",
    "    # Define transforms\n",
    "    train_transforms = Compose([\n",
    "        ScaleIntensity(),\n",
    "        AddChannel(),\n",
    "        RandRotate(range_x=10.0, range_y=10.0, range_z=10.0, prob=0.5),\n",
    "        SpatialPad((256, 256, 92), mode='constant'),\n",
    "        SpatialCrop((256, 256, 92),roi_start=(0, 0, 0), roi_end=(255, 255, 91)),\n",
    "        ToTensor()\n",
    "    ])\n",
    "    \n",
    "    val_transforms = Compose([\n",
    "        ScaleIntensity(),\n",
    "        AddChannel(),\n",
    "        SpatialPad((256, 256, 92), mode='constant'),\n",
    "        SpatialCrop((256, 256, 92),roi_start=(0, 0, 0), roi_end=(255, 255, 91)),\n",
    "        ToTensor()\n",
    "    ])\n",
    "\n",
    "    # create a training data loader\n",
    "    train_ds = NiftiDataset(image_files=train_images, labels=train_labels, transform=train_transforms)\n",
    "    train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=2, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "    # create a validation data loader\n",
    "    val_ds = NiftiDataset(image_files=val_images, labels=val_labels, transform=val_transforms)\n",
    "    val_loader = DataLoader(val_ds, batch_size=2, num_workers=2, pin_memory=torch.cuda.is_available())\n",
    "    \n",
    "    # Create DenseNet121, CrossEntropyLoss and Adam optimizer\n",
    "    device = torch.device('cuda:0')\n",
    "    model = monai.networks.nets.densenet.densenet121(\n",
    "        spatial_dims=3,\n",
    "        in_channels=1,\n",
    "        out_channels=2,\n",
    "    ).to(device)\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), 1e-2)\n",
    "    \n",
    "    # finetuning\n",
    "    #model.load_state_dict(torch.load('best_metric_model_d121.pth'))\n",
    "\n",
    "    # start a typical PyTorch training\n",
    "    val_interval = 1\n",
    "    best_metric = -1\n",
    "    best_metric_epoch = -1\n",
    "    epoch_loss_values = list()\n",
    "    metric_values = list()\n",
    "    writer = SummaryWriter()\n",
    "    epc = 100 # Number of epoch\n",
    "    for epoch in range(epc):\n",
    "        print('-' * 10)\n",
    "        print('epoch {}/{}'.format(epoch + 1, epc))\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        step = 0\n",
    "        for batch_data in train_loader:\n",
    "            step += 1\n",
    "            inputs, labels = batch_data[0].to(device), batch_data[1].to(device=device, dtype=torch.int64)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_len = len(train_ds) // train_loader.batch_size\n",
    "            print('{}/{}, train_loss: {:.4f}'.format(step, epoch_len, loss.item()))\n",
    "            writer.add_scalar('train_loss', loss.item(), epoch_len * epoch + step)\n",
    "        epoch_loss /= step\n",
    "        epoch_loss_values.append(epoch_loss)\n",
    "        print('epoch {} average loss: {:.4f}'.format(epoch + 1, epoch_loss))\n",
    "\n",
    "        if (epoch + 1) % val_interval == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                num_correct = 0.\n",
    "                metric_count = 0\n",
    "                for val_data in val_loader:\n",
    "                    val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
    "                    val_outputs = model(val_images)\n",
    "                    value = torch.eq(val_outputs.argmax(dim=1), val_labels)\n",
    "                    metric_count += len(value)\n",
    "                    num_correct += value.sum().item()\n",
    "                metric = num_correct / metric_count\n",
    "                metric_values.append(metric)\n",
    "                #torch.save(model.state_dict(), 'model_d121_epoch_{}.pth'.format(epoch + 1))\n",
    "                if metric > best_metric:\n",
    "                    best_metric = metric\n",
    "                    best_metric_epoch = epoch + 1\n",
    "                    torch.save(model.state_dict(), '/home/marafath/scratch/saved_models/best_metric_model_d121.pth')\n",
    "                    print('saved new best metric model')\n",
    "                print('current epoch: {} current accuracy: {:.4f} best accuracy: {:.4f} at epoch {}'.format(\n",
    "                    epoch + 1, metric, best_metric, best_metric_epoch))\n",
    "                writer.add_scalar('val_accuracy', metric, epoch + 1)\n",
    "    print('train completed, best_metric: {:.4f} at epoch: {}'.format(best_metric, best_metric_epoch))\n",
    "    writer.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
