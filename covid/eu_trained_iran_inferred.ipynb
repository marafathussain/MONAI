{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import monai\n",
    "from monai.data import NiftiDataset, CSVSaver\n",
    "from monai.transforms import Compose, AddChannel, ScaleIntensity, Resize, ToTensor, SpatialPad\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def main():\n",
    "    monai.config.print_config()\n",
    "    logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "    \n",
    "    images = []\n",
    "    labels = []\n",
    "    class_names = ['Pneumonia', 'Healthy']\n",
    "\n",
    "    data_dir = '/home/marafath/scratch/iran_organized_data2'\n",
    "    for patient in os.listdir(data_dir):\n",
    "        label = int(patient[-1])\n",
    "        for series in os.listdir(os.path.join(data_dir,patient)):\n",
    "            images.append(os.path.join(data_dir,patient,series,'masked_image.nii.gz'))\n",
    "            labels.append(label)\n",
    "\n",
    "    labels = np.asarray(labels,np.int64)\n",
    "\n",
    "    # Define transforms for image\n",
    "    val_transforms = Compose([\n",
    "        ScaleIntensity(),\n",
    "        AddChannel(),\n",
    "        SpatialPad((256, 256, 92), mode='constant'),\n",
    "        Resize((256, 256, 92)),\n",
    "        ToTensor()\n",
    "    ])\n",
    "\n",
    "    # create a validation data loader\n",
    "    val_ds = NiftiDataset(image_files=images, labels=labels, transform=val_transforms, image_only=False)\n",
    "    val_loader = DataLoader(val_ds, batch_size=2, num_workers=2, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "    # Create DenseNet121\n",
    "    device = torch.device('cuda:0')\n",
    "    model = monai.networks.nets.densenet.densenet121(\n",
    "        spatial_dims=3,\n",
    "        in_channels=1,\n",
    "        out_channels=2,\n",
    "    ).to(device)\n",
    "\n",
    "    model.load_state_dict(torch.load(\"/home/marafath/scratch/saved_models/best_metric_model_d121.pth\"))\n",
    "    model.eval()\n",
    "    \n",
    "    y_true = list()\n",
    "    y_pred = list()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        num_correct = 0.\n",
    "        metric_count = 0\n",
    "        saver = CSVSaver(output_dir='./output')\n",
    "        for val_data in val_loader:\n",
    "            val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
    "            val_outputs = model(val_images).argmax(dim=1)\n",
    "            value = torch.eq(val_outputs, val_labels)\n",
    "            metric_count += len(value)\n",
    "            num_correct += value.sum().item()\n",
    "            saver.save_batch(val_outputs, val_data[2])\n",
    "            \n",
    "            for i in range(len(val_outputs)):\n",
    "                y_true.append(val_labels[i].item())\n",
    "                y_pred.append(val_outputs[i].item())\n",
    "            \n",
    "        metric = num_correct / metric_count\n",
    "        print('evaluation metric:', metric)\n",
    "        print(classification_report(y_true, y_pred, target_names=class_names, digits=4))\n",
    "        saver.finalize()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
