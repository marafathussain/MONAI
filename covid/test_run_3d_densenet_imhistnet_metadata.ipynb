{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import Callable, Sequence\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import sys\n",
    "import logging\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import monai\n",
    "from monai.data import NiftiDataset\n",
    "from monai.transforms import Compose, SpatialPad, AddChannel, ScaleIntensity, Resize, RandRotate90, RandRotate, RandZoom, ToTensor\n",
    "import os\n",
    "from my_dataloader import NiftiDataset2\n",
    "\n",
    "\n",
    "from monai.networks.layers.factories import Conv, Dropout, Pool, Norm\n",
    "\n",
    "\n",
    "class _DenseLayer(nn.Sequential):\n",
    "    def __init__(\n",
    "        self, spatial_dims: int, in_channels: int, growth_rate: int, bn_size: int, dropout_prob: float\n",
    "    ) -> None:\n",
    "        super(_DenseLayer, self).__init__()\n",
    "\n",
    "        out_channels = bn_size * growth_rate\n",
    "        conv_type: Callable = Conv[Conv.CONV, spatial_dims]\n",
    "        norm_type: Callable = Norm[Norm.BATCH, spatial_dims]\n",
    "        dropout_type: Callable = Dropout[Dropout.DROPOUT, spatial_dims]\n",
    "\n",
    "        self.add_module(\"norm1\", norm_type(in_channels))\n",
    "        self.add_module(\"relu1\", nn.ReLU(inplace=True))\n",
    "        self.add_module(\"conv1\", conv_type(in_channels, out_channels, kernel_size=1, bias=False))\n",
    "\n",
    "        self.add_module(\"norm2\", norm_type(out_channels))\n",
    "        self.add_module(\"relu2\", nn.ReLU(inplace=True))\n",
    "        self.add_module(\"conv2\", conv_type(out_channels, growth_rate, kernel_size=3, padding=1, bias=False))\n",
    "\n",
    "        if dropout_prob > 0:\n",
    "            self.add_module(\"dropout\", dropout_type(dropout_prob))\n",
    "\n",
    "    def forward(self, x):\n",
    "        new_features = super(_DenseLayer, self).forward(x)\n",
    "        return torch.cat([x, new_features], 1)\n",
    "\n",
    "\n",
    "class _DenseBlock(nn.Sequential):\n",
    "    def __init__(\n",
    "        self, spatial_dims: int, layers: int, in_channels: int, bn_size: int, growth_rate: int, dropout_prob: float\n",
    "    ) -> None:\n",
    "        super(_DenseBlock, self).__init__()\n",
    "        for i in range(layers):\n",
    "            layer = _DenseLayer(spatial_dims, in_channels, growth_rate, bn_size, dropout_prob)\n",
    "            in_channels += growth_rate\n",
    "            self.add_module(\"denselayer%d\" % (i + 1), layer)\n",
    "\n",
    "\n",
    "class _Transition(nn.Sequential):\n",
    "    def __init__(self, spatial_dims: int, in_channels: int, out_channels: int) -> None:\n",
    "        super(_Transition, self).__init__()\n",
    "\n",
    "        conv_type: Callable = Conv[Conv.CONV, spatial_dims]\n",
    "        norm_type: Callable = Norm[Norm.BATCH, spatial_dims]\n",
    "        pool_type: Callable = Pool[Pool.AVG, spatial_dims]\n",
    "\n",
    "        self.add_module(\"norm\", norm_type(in_channels))\n",
    "        self.add_module(\"relu\", nn.ReLU(inplace=True))\n",
    "        self.add_module(\"conv\", conv_type(in_channels, out_channels, kernel_size=1, bias=False))\n",
    "        self.add_module(\"pool\", pool_type(kernel_size=2, stride=2))\n",
    "\n",
    "\n",
    "class DenseNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Densenet based on: \"Densely Connected Convolutional Networks\" https://arxiv.org/pdf/1608.06993.pdf\n",
    "    Adapted from PyTorch Hub 2D version:\n",
    "    https://github.com/pytorch/vision/blob/master/torchvision/models/densenet.py\n",
    "\n",
    "    Args:\n",
    "        spatial_dims: number of spatial dimensions of the input image.\n",
    "        in_channels: number of the input channel.\n",
    "        out_channels: number of the output classes.\n",
    "        init_features: number of filters in the first convolution layer.\n",
    "        growth_rate: how many filters to add each layer (k in paper).\n",
    "        block_config: how many layers in each pooling block.\n",
    "        bn_size: multiplicative factor for number of bottle neck layers.\n",
    "                      (i.e. bn_size * k features in the bottleneck layer)\n",
    "        dropout_prob: dropout rate after each dense layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        spatial_dims: int,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        init_features: int = 64,\n",
    "        growth_rate: int = 32,\n",
    "        block_config: Sequence[int] = (6, 12, 24, 16),\n",
    "        bn_size: int = 4,\n",
    "        dropout_prob: float = 0.0,\n",
    "        bins=8,\n",
    "        pool_kernel=32,\n",
    "        pool_stride=32\n",
    "    ) -> None:\n",
    "\n",
    "        super(DenseNet, self).__init__()\n",
    "\n",
    "        conv_type: Callable = Conv[Conv.CONV, spatial_dims]\n",
    "        norm_type: Callable = Norm[Norm.BATCH, spatial_dims]\n",
    "        pool_type: Callable = Pool[Pool.MAX, spatial_dims]\n",
    "        avg_pool_type: Callable = Pool[Pool.ADAPTIVEAVG, spatial_dims]\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\"conv0\", conv_type(in_channels, init_features, kernel_size=7, stride=2, padding=3, bias=False)),\n",
    "                    (\"norm0\", norm_type(init_features)),\n",
    "                    (\"relu0\", nn.ReLU(inplace=True)),\n",
    "                    (\"pool0\", pool_type(kernel_size=3, stride=2, padding=1)),\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        in_channels = init_features\n",
    "        for i, num_layers in enumerate(block_config):\n",
    "            block = _DenseBlock(\n",
    "                spatial_dims=spatial_dims,\n",
    "                layers=num_layers,\n",
    "                in_channels=in_channels,\n",
    "                bn_size=bn_size,\n",
    "                growth_rate=growth_rate,\n",
    "                dropout_prob=dropout_prob,\n",
    "            )\n",
    "            self.features.add_module(\"denseblock%d\" % (i + 1), block)\n",
    "            in_channels += num_layers * growth_rate\n",
    "            if i == len(block_config) - 1:\n",
    "                self.features.add_module(\"norm5\", norm_type(in_channels))\n",
    "            else:\n",
    "                _out_channels = in_channels // 2\n",
    "                trans = _Transition(spatial_dims, in_channels=in_channels, out_channels=_out_channels)\n",
    "                self.features.add_module(\"transition%d\" % (i + 1), trans)\n",
    "                in_channels = _out_channels\n",
    "\n",
    "        # pooling and classification\n",
    "        '''\n",
    "        self.class_layers = nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\"relu\", nn.ReLU(inplace=True)),\n",
    "                    (\"norm\", avg_pool_type(1)),\n",
    "                    (\"flatten\", nn.Flatten(1)), \n",
    "                    (\"class\", nn.Linear(in_channels, out_channels)),\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        '''\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc1 = nn.Linear(1024*4*4*4, 1024)\n",
    "        self.fc2 = nn.Linear(1024+1024+107, 1024)\n",
    "        self.fc3 = nn.Linear(1024, out_channels)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, conv_type):  # type: ignore\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, norm_type):  # type: ignore\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "        # 3D-ImHistNet\n",
    "        self.conv1 = nn.Conv3d(1, bins, 1, 1)\n",
    "        nn.init.constant_(self.conv1.weight, 1.0)\n",
    "        \n",
    "        \n",
    "        self.conv2 = nn.Conv3d(bins, bins, 1, 1, groups=bins)\n",
    "        nn.init.constant_(self.conv2.bias, 1.0)\n",
    "    \n",
    "        self.avgpool = nn.AvgPool3d(pool_kernel, pool_stride)\n",
    "        self.hist_fc = nn.Linear(bins*4*4*4, 1024)\n",
    "        #self.fc2 = nn.Linear(1024, no_classes)\n",
    "\n",
    "        #initialize_params(self)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x1 = self.features(x)\n",
    "        x1 = torch.flatten(x1, 1)\n",
    "        x1 = self.fc1(x1)\n",
    "        \n",
    "        x2 = self.conv1(x)\n",
    "        x2 = torch.abs(x2)\n",
    "        x2 = self.conv2(x2)\n",
    "        x2 = self.relu(x2)\n",
    "        x2 = self.avgpool(x2)\n",
    "        x2 = torch.flatten(x2, 1)\n",
    "        x2 = self.hist_fc(x2)\n",
    "        \n",
    "        y = torch.flatten(y, 1)\n",
    "        \n",
    "        x_cat = torch.cat([x1, x2, y], 1)\n",
    "        x_cat = self.fc2(x_cat)\n",
    "        x_cat = self.fc3(x_cat)\n",
    "        return x_cat\n",
    "\n",
    "\n",
    "def densenet121(**kwargs) -> DenseNet:\n",
    "    model = DenseNet(init_features=64, growth_rate=32, block_config=(6, 12, 24, 16), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def densenet169(**kwargs) -> DenseNet:\n",
    "    model = DenseNet(init_features=64, growth_rate=32, block_config=(6, 12, 32, 32), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def densenet201(**kwargs) -> DenseNet:\n",
    "    model = DenseNet(init_features=64, growth_rate=32, block_config=(6, 12, 48, 32), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def densenet264(**kwargs) -> DenseNet:\n",
    "    model = DenseNet(init_features=64, growth_rate=32, block_config=(6, 12, 64, 48), **kwargs)\n",
    "    return model\n",
    "\n",
    "def main():\n",
    "    monai.config.print_config()\n",
    "    logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "    print('Iran data: cropped and common resized, densenet+imhistnet-8bins+radiomics')\n",
    "\n",
    "    # Training data paths\n",
    "    data_dir = '/home/marafath/scratch/iran_organized_data2'\n",
    "\n",
    "    covid_pat = 0\n",
    "    non_covid_pat = 0\n",
    "\n",
    "    images_p = []\n",
    "    labels_p = []\n",
    "    metadata_p = []\n",
    "    images_n = []\n",
    "    labels_n = []\n",
    "    metadata_n = []\n",
    "\n",
    "    for patient in os.listdir(data_dir):\n",
    "        if int(patient[-1]) == 0 and non_covid_pat > 236:\n",
    "            continue \n",
    "\n",
    "        if int(patient[-1]) == 1:\n",
    "            covid_pat += 1\n",
    "            for series in os.listdir(os.path.join(data_dir,patient)):\n",
    "                labels_p.append(1)\n",
    "                images_p.append(os.path.join(data_dir,patient,series,'cropped_and_resized_image.nii.gz'))\n",
    "                metadata_p.append(os.path.join(data_dir,patient,series,'radiomics.npy'))\n",
    "        else:\n",
    "            non_covid_pat += 1\n",
    "            for series in os.listdir(os.path.join(data_dir,patient)):\n",
    "                labels_n.append(0)\n",
    "                images_n.append(os.path.join(data_dir,patient,series,'cropped_and_resized_image.nii.gz'))\n",
    "                metadata_n.append(os.path.join(data_dir,patient,series,'radiomics.npy'))\n",
    "            \n",
    "    train_images = []\n",
    "    train_meta = []\n",
    "    train_labels = []\n",
    "\n",
    "    val_images = []\n",
    "    val_meta = []\n",
    "    val_labels = []\n",
    "\n",
    "    for i in range(0,len(images_p)):\n",
    "        if i < 407:\n",
    "            train_images.append(images_p[i])\n",
    "            train_meta.append(metadata_p[i])\n",
    "            train_labels.append(labels_p[i])\n",
    "        else:\n",
    "            val_images.append(images_p[i])\n",
    "            val_meta.append(metadata_p[i])\n",
    "            val_labels.append(labels_p[i])\n",
    "\n",
    "    for i in range(0,len(images_n)):\n",
    "        if i < 405:\n",
    "            train_images.append(images_n[i])\n",
    "            train_meta.append(metadata_n[i])\n",
    "            train_labels.append(labels_n[i])\n",
    "        else:\n",
    "            val_images.append(images_n[i])\n",
    "            val_meta.append(metadata_n[i])\n",
    "            val_labels.append(labels_n[i])  \n",
    "    \n",
    "    train_labels = np.asarray(train_labels,np.int64)\n",
    "    val_labels = np.asarray(val_labels,np.int64)\n",
    "\n",
    "    # Define transforms\n",
    "    train_transforms = Compose([\n",
    "        ScaleIntensity(),\n",
    "        AddChannel(),\n",
    "        RandRotate(range_x=10.0, range_y=10.0, range_z=10.0, prob=0.5),\n",
    "        RandZoom(min_zoom=0.9, max_zoom=1.1, prob=0.5),\n",
    "        #SpatialPad((128, 128, 92), mode='constant'),\n",
    "        #Resize((128, 128, 92)),\n",
    "        ToTensor()\n",
    "    ])\n",
    "    \n",
    "    val_transforms = Compose([\n",
    "        ScaleIntensity(),\n",
    "        AddChannel(),\n",
    "        #SpatialPad((128, 128, 92), mode='constant'),\n",
    "        #Resize((128, 128, 92)),\n",
    "        ToTensor()\n",
    "    ])\n",
    "\n",
    "    # create a training data loader\n",
    "    train_ds = NiftiDataset2(image_files=train_images, patient_data=train_meta, labels=train_labels, transform=train_transforms)\n",
    "    train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=2, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "    # create a validation data loader\n",
    "    val_ds = NiftiDataset2(image_files=val_images, patient_data=val_meta, labels=val_labels, transform=val_transforms)\n",
    "    val_loader = DataLoader(val_ds, batch_size=2, num_workers=2, pin_memory=torch.cuda.is_available())\n",
    "    \n",
    "    device = torch.device('cuda:0')\n",
    "    model = densenet121(\n",
    "        spatial_dims=3,\n",
    "        in_channels=1,\n",
    "        out_channels=2,\n",
    "    ).to(device)\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "    \n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), 1e-3)\n",
    "    \n",
    "    # finetuning\n",
    "    #model.load_state_dict(torch.load('best_metric_model_d121.pth'))\n",
    "\n",
    "    # start a typical PyTorch training\n",
    "    val_interval = 1\n",
    "    best_metric = -1\n",
    "    best_metric_epoch = -1\n",
    "    epoch_loss_values = list()\n",
    "    metric_values = list()\n",
    "    writer = SummaryWriter()\n",
    "    epc = 300 # Number of epoch\n",
    "    for epoch in range(epc):\n",
    "        print('-' * 10)\n",
    "        print('epoch {}/{}'.format(epoch + 1, epc))\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        step = 0\n",
    "        for batch_data in train_loader:\n",
    "            step += 1\n",
    "            input1, input2, labels = batch_data[0].to(device), batch_data[1].to(device), \\\n",
    "                                     batch_data[2].to(device=device, dtype=torch.int64)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input1, input2.float())\n",
    "            loss = loss_function(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_len = len(train_ds) // train_loader.batch_size\n",
    "            print('{}/{}, train_loss: {:.4f}'.format(step, epoch_len, loss.item()))\n",
    "            writer.add_scalar('train_loss', loss.item(), epoch_len * epoch + step)\n",
    "        epoch_loss /= step\n",
    "        epoch_loss_values.append(epoch_loss)\n",
    "        print('epoch {} average loss: {:.4f}'.format(epoch + 1, epoch_loss))\n",
    "\n",
    "        if (epoch + 1) % val_interval == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                num_correct = 0.\n",
    "                metric_count = 0\n",
    "                for val_data in val_loader:\n",
    "                    val_images1, val_images2, val_labels = val_data[0].to(device), val_data[1].to(device), val_data[2].to(device)\n",
    "                    val_outputs = model(val_images1, val_images2)\n",
    "                    value = torch.eq(val_outputs.argmax(dim=1), val_labels)\n",
    "                    metric_count += len(value)\n",
    "                    num_correct += value.sum().item()\n",
    "                metric = num_correct / metric_count\n",
    "                metric_values.append(metric)\n",
    "                #torch.save(model.state_dict(), 'model_d121_epoch_{}.pth'.format(epoch + 1))\n",
    "                if metric > best_metric:\n",
    "                    best_metric = metric\n",
    "                    best_metric_epoch = epoch + 1\n",
    "                    torch.save(model.state_dict(), '/home/marafath/scratch/saved_models/best_d121_imhistnet8_radiomics.pth')\n",
    "                    print('saved new best metric model')\n",
    "                print('current epoch: {} current accuracy: {:.4f} best accuracy: {:.4f} at epoch {}'.format(\n",
    "                    epoch + 1, metric, best_metric, best_metric_epoch))\n",
    "                writer.add_scalar('val_accuracy', metric, epoch + 1)\n",
    "    print('train completed, best_metric: {:.4f} at epoch: {}'.format(best_metric, best_metric_epoch))\n",
    "    writer.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/marafath/scratch/iran_organized_data2'\n",
    "\n",
    "for patient in os.listdir(data_dir):\n",
    "    for series in os.listdir(os.path.join(data_dir,patient)):\n",
    "        data = np.load(os.path.join(data_dir,patient,series,'radiomics.npy'))\n",
    "        print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
