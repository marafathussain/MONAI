{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 0.1.0+626.g63eec3a.dirty\n",
      "Python version: 3.7.4 (default, Jul 18 2019, 19:34:02)  [GCC 5.4.0]\n",
      "Numpy version: 1.18.1\n",
      "Pytorch version: 1.5.0\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.3.0\n",
      "Nibabel version: 3.1.0\n",
      "scikit-image version: 0.14.2\n",
      "Pillow version: 7.0.0\n",
      "Tensorboard version: 2.3.0\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n",
      "Iran data: cropped and common resized, densenet+imhistnet-8bins\n",
      "----------\n",
      "epoch 1/300\n",
      "1/203, train_loss: 0.6158\n",
      "2/203, train_loss: 57.2829\n",
      "3/203, train_loss: 175.5821\n",
      "4/203, train_loss: 59.1700\n",
      "5/203, train_loss: 0.0000\n",
      "6/203, train_loss: 23.8266\n",
      "7/203, train_loss: 139.7930\n",
      "8/203, train_loss: 63.2382\n",
      "9/203, train_loss: 0.0021\n",
      "10/203, train_loss: 0.0017\n",
      "11/203, train_loss: 62.0368\n",
      "12/203, train_loss: 8.5916\n",
      "13/203, train_loss: 3.9488\n",
      "14/203, train_loss: 7.8267\n",
      "15/203, train_loss: 116.7465\n",
      "16/203, train_loss: 22.8197\n",
      "17/203, train_loss: 54.6646\n",
      "18/203, train_loss: 23.0237\n",
      "19/203, train_loss: 50.0293\n",
      "20/203, train_loss: 36.1439\n",
      "21/203, train_loss: 18.5924\n",
      "22/203, train_loss: 21.2373\n",
      "23/203, train_loss: 29.1491\n",
      "24/203, train_loss: 31.3410\n",
      "25/203, train_loss: 11.8963\n",
      "26/203, train_loss: 0.9319\n",
      "27/203, train_loss: 3.9764\n",
      "28/203, train_loss: 4.9094\n",
      "29/203, train_loss: 5.5307\n",
      "30/203, train_loss: 4.7285\n",
      "31/203, train_loss: 3.0445\n",
      "32/203, train_loss: 12.6377\n",
      "33/203, train_loss: 7.3825\n",
      "34/203, train_loss: 2.8452\n",
      "35/203, train_loss: 23.6209\n",
      "36/203, train_loss: 8.0702\n",
      "37/203, train_loss: 9.1392\n",
      "38/203, train_loss: 5.2198\n",
      "39/203, train_loss: 0.2888\n",
      "40/203, train_loss: 6.7892\n",
      "41/203, train_loss: 0.3702\n",
      "42/203, train_loss: 3.1104\n",
      "43/203, train_loss: 4.8027\n",
      "44/203, train_loss: 23.4978\n",
      "45/203, train_loss: 12.2842\n",
      "46/203, train_loss: 1.8895\n",
      "47/203, train_loss: 15.0763\n",
      "48/203, train_loss: 9.5242\n",
      "49/203, train_loss: 1.9366\n",
      "50/203, train_loss: 13.6004\n",
      "51/203, train_loss: 7.1469\n",
      "52/203, train_loss: 24.3608\n",
      "53/203, train_loss: 0.8284\n",
      "54/203, train_loss: 21.5848\n",
      "55/203, train_loss: 4.1322\n",
      "56/203, train_loss: 5.3124\n",
      "57/203, train_loss: 3.4513\n",
      "58/203, train_loss: 1.9744\n",
      "59/203, train_loss: 2.8410\n",
      "60/203, train_loss: 5.1853\n",
      "61/203, train_loss: 7.0943\n",
      "62/203, train_loss: 4.2744\n",
      "63/203, train_loss: 1.9904\n",
      "64/203, train_loss: 0.0383\n",
      "65/203, train_loss: 0.0068\n",
      "66/203, train_loss: 5.6719\n",
      "67/203, train_loss: 1.5414\n",
      "68/203, train_loss: 6.0176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-83e7873d97c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-83e7873d97c8>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ENV/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ENV/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import Callable, Sequence\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import sys\n",
    "import logging\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import monai\n",
    "from monai.data import NiftiDataset\n",
    "from monai.transforms import Compose, SpatialPad, AddChannel, ScaleIntensity, Resize, RandRotate90, RandRotate, RandZoom, ToTensor\n",
    "import os\n",
    "\n",
    "\n",
    "from monai.networks.layers.factories import Conv, Dropout, Pool, Norm\n",
    "\n",
    "\n",
    "class _DenseLayer(nn.Sequential):\n",
    "    def __init__(\n",
    "        self, spatial_dims: int, in_channels: int, growth_rate: int, bn_size: int, dropout_prob: float\n",
    "    ) -> None:\n",
    "        super(_DenseLayer, self).__init__()\n",
    "\n",
    "        out_channels = bn_size * growth_rate\n",
    "        conv_type: Callable = Conv[Conv.CONV, spatial_dims]\n",
    "        norm_type: Callable = Norm[Norm.BATCH, spatial_dims]\n",
    "        dropout_type: Callable = Dropout[Dropout.DROPOUT, spatial_dims]\n",
    "\n",
    "        self.add_module(\"norm1\", norm_type(in_channels))\n",
    "        self.add_module(\"relu1\", nn.ReLU(inplace=True))\n",
    "        self.add_module(\"conv1\", conv_type(in_channels, out_channels, kernel_size=1, bias=False))\n",
    "\n",
    "        self.add_module(\"norm2\", norm_type(out_channels))\n",
    "        self.add_module(\"relu2\", nn.ReLU(inplace=True))\n",
    "        self.add_module(\"conv2\", conv_type(out_channels, growth_rate, kernel_size=3, padding=1, bias=False))\n",
    "\n",
    "        if dropout_prob > 0:\n",
    "            self.add_module(\"dropout\", dropout_type(dropout_prob))\n",
    "\n",
    "    def forward(self, x):\n",
    "        new_features = super(_DenseLayer, self).forward(x)\n",
    "        return torch.cat([x, new_features], 1)\n",
    "\n",
    "\n",
    "class _DenseBlock(nn.Sequential):\n",
    "    def __init__(\n",
    "        self, spatial_dims: int, layers: int, in_channels: int, bn_size: int, growth_rate: int, dropout_prob: float\n",
    "    ) -> None:\n",
    "        super(_DenseBlock, self).__init__()\n",
    "        for i in range(layers):\n",
    "            layer = _DenseLayer(spatial_dims, in_channels, growth_rate, bn_size, dropout_prob)\n",
    "            in_channels += growth_rate\n",
    "            self.add_module(\"denselayer%d\" % (i + 1), layer)\n",
    "\n",
    "\n",
    "class _Transition(nn.Sequential):\n",
    "    def __init__(self, spatial_dims: int, in_channels: int, out_channels: int) -> None:\n",
    "        super(_Transition, self).__init__()\n",
    "\n",
    "        conv_type: Callable = Conv[Conv.CONV, spatial_dims]\n",
    "        norm_type: Callable = Norm[Norm.BATCH, spatial_dims]\n",
    "        pool_type: Callable = Pool[Pool.AVG, spatial_dims]\n",
    "\n",
    "        self.add_module(\"norm\", norm_type(in_channels))\n",
    "        self.add_module(\"relu\", nn.ReLU(inplace=True))\n",
    "        self.add_module(\"conv\", conv_type(in_channels, out_channels, kernel_size=1, bias=False))\n",
    "        self.add_module(\"pool\", pool_type(kernel_size=2, stride=2))\n",
    "\n",
    "\n",
    "class DenseNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Densenet based on: \"Densely Connected Convolutional Networks\" https://arxiv.org/pdf/1608.06993.pdf\n",
    "    Adapted from PyTorch Hub 2D version:\n",
    "    https://github.com/pytorch/vision/blob/master/torchvision/models/densenet.py\n",
    "\n",
    "    Args:\n",
    "        spatial_dims: number of spatial dimensions of the input image.\n",
    "        in_channels: number of the input channel.\n",
    "        out_channels: number of the output classes.\n",
    "        init_features: number of filters in the first convolution layer.\n",
    "        growth_rate: how many filters to add each layer (k in paper).\n",
    "        block_config: how many layers in each pooling block.\n",
    "        bn_size: multiplicative factor for number of bottle neck layers.\n",
    "                      (i.e. bn_size * k features in the bottleneck layer)\n",
    "        dropout_prob: dropout rate after each dense layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        spatial_dims: int,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        init_features: int = 64,\n",
    "        growth_rate: int = 32,\n",
    "        block_config: Sequence[int] = (6, 12, 24, 16),\n",
    "        bn_size: int = 4,\n",
    "        dropout_prob: float = 0.0,\n",
    "        bins=8,\n",
    "        pool_kernel=32,\n",
    "        pool_stride=32\n",
    "    ) -> None:\n",
    "\n",
    "        super(DenseNet, self).__init__()\n",
    "\n",
    "        conv_type: Callable = Conv[Conv.CONV, spatial_dims]\n",
    "        norm_type: Callable = Norm[Norm.BATCH, spatial_dims]\n",
    "        pool_type: Callable = Pool[Pool.MAX, spatial_dims]\n",
    "        avg_pool_type: Callable = Pool[Pool.ADAPTIVEAVG, spatial_dims]\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\"conv0\", conv_type(in_channels, init_features, kernel_size=7, stride=2, padding=3, bias=False)),\n",
    "                    (\"norm0\", norm_type(init_features)),\n",
    "                    (\"relu0\", nn.ReLU(inplace=True)),\n",
    "                    (\"pool0\", pool_type(kernel_size=3, stride=2, padding=1)),\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        in_channels = init_features\n",
    "        for i, num_layers in enumerate(block_config):\n",
    "            block = _DenseBlock(\n",
    "                spatial_dims=spatial_dims,\n",
    "                layers=num_layers,\n",
    "                in_channels=in_channels,\n",
    "                bn_size=bn_size,\n",
    "                growth_rate=growth_rate,\n",
    "                dropout_prob=dropout_prob,\n",
    "            )\n",
    "            self.features.add_module(\"denseblock%d\" % (i + 1), block)\n",
    "            in_channels += num_layers * growth_rate\n",
    "            if i == len(block_config) - 1:\n",
    "                self.features.add_module(\"norm5\", norm_type(in_channels))\n",
    "            else:\n",
    "                _out_channels = in_channels // 2\n",
    "                trans = _Transition(spatial_dims, in_channels=in_channels, out_channels=_out_channels)\n",
    "                self.features.add_module(\"transition%d\" % (i + 1), trans)\n",
    "                in_channels = _out_channels\n",
    "\n",
    "        # pooling and classification\n",
    "        '''\n",
    "        self.class_layers = nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\"relu\", nn.ReLU(inplace=True)),\n",
    "                    (\"norm\", avg_pool_type(1)),\n",
    "                    (\"flatten\", nn.Flatten(1)), \n",
    "                    (\"class\", nn.Linear(in_channels, out_channels)),\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        '''\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc1 = nn.Linear(1024*4*4*4, 1024)\n",
    "        self.fc2 = nn.Linear(2048, out_channels)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, conv_type):  # type: ignore\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, norm_type):  # type: ignore\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "        # 3D-ImHistNet\n",
    "        self.conv1 = nn.Conv3d(1, bins, 1, 1)\n",
    "        nn.init.constant_(self.conv1.weight, 1.0)\n",
    "        \n",
    "        \n",
    "        self.conv2 = nn.Conv3d(bins, bins, 1, 1, groups=bins)\n",
    "        nn.init.constant_(self.conv2.bias, 1.0)\n",
    "    \n",
    "        self.avgpool = nn.AvgPool3d(pool_kernel, pool_stride)\n",
    "        self.hist_fc = nn.Linear(bins*4*4*4, 1024)\n",
    "        #self.fc2 = nn.Linear(1024, no_classes)\n",
    "\n",
    "        #initialize_params(self)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.features(x)\n",
    "        x1 = torch.flatten(x1, 1)\n",
    "        x1 = self.fc1(x1)\n",
    "        \n",
    "        x2 = self.conv1(x)\n",
    "        x2 = torch.abs(x2)\n",
    "        x2 = self.conv2(x2)\n",
    "        x2 = self.relu(x2)\n",
    "        x2 = self.avgpool(x2)\n",
    "        x2 = torch.flatten(x2, 1)\n",
    "        x2 = self.hist_fc(x2)\n",
    "        \n",
    "        x_cat = torch.cat([x1, x2], 1)\n",
    "        x_cat = self.fc2(x_cat)\n",
    "        return x_cat\n",
    "\n",
    "\n",
    "def densenet121(**kwargs) -> DenseNet:\n",
    "    model = DenseNet(init_features=64, growth_rate=32, block_config=(6, 12, 24, 16), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def densenet169(**kwargs) -> DenseNet:\n",
    "    model = DenseNet(init_features=64, growth_rate=32, block_config=(6, 12, 32, 32), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def densenet201(**kwargs) -> DenseNet:\n",
    "    model = DenseNet(init_features=64, growth_rate=32, block_config=(6, 12, 48, 32), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def densenet264(**kwargs) -> DenseNet:\n",
    "    model = DenseNet(init_features=64, growth_rate=32, block_config=(6, 12, 64, 48), **kwargs)\n",
    "    return model\n",
    "\n",
    "def main():\n",
    "    monai.config.print_config()\n",
    "    logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "    print('Iran data: cropped and common resized, densenet+imhistnet-8bins')\n",
    "\n",
    "    # Training data paths\n",
    "    data_dir = '/home/marafath/scratch/iran_organized_data2'\n",
    "\n",
    "    covid_pat = 0\n",
    "    non_covid_pat = 0\n",
    "\n",
    "    images_p = []\n",
    "    labels_p = []\n",
    "    images_n = []\n",
    "    labels_n = []\n",
    "\n",
    "    for patient in os.listdir(data_dir):\n",
    "        if int(patient[-1]) == 0 and non_covid_pat > 236:\n",
    "            continue \n",
    "\n",
    "        if int(patient[-1]) == 1:\n",
    "            covid_pat += 1\n",
    "            for series in os.listdir(os.path.join(data_dir,patient)):\n",
    "                labels_p.append(1)\n",
    "                images_p.append(os.path.join(data_dir,patient,series,'cropped_and_resized_image.nii.gz'))\n",
    "        else:\n",
    "            non_covid_pat += 1\n",
    "            for series in os.listdir(os.path.join(data_dir,patient)):\n",
    "                labels_n.append(0)\n",
    "                images_n.append(os.path.join(data_dir,patient,series,'cropped_and_resized_image.nii.gz'))\n",
    "            \n",
    "    train_images = []\n",
    "    train_labels = []\n",
    "\n",
    "    val_images = []\n",
    "    val_labels = []\n",
    "\n",
    "    for i in range(0,len(images_p)):\n",
    "        if i < 407:\n",
    "            train_images.append(images_p[i])\n",
    "            train_labels.append(labels_p[i])\n",
    "        else:\n",
    "            val_images.append(images_p[i])\n",
    "            val_labels.append(labels_p[i])\n",
    "\n",
    "    for i in range(0,len(images_n)):\n",
    "        if i < 405:\n",
    "            train_images.append(images_n[i])\n",
    "            train_labels.append(labels_n[i])\n",
    "        else:\n",
    "            val_images.append(images_n[i])\n",
    "            val_labels.append(labels_n[i])  \n",
    "    \n",
    "    train_labels = np.asarray(train_labels,np.int64)\n",
    "    val_labels = np.asarray(val_labels,np.int64)\n",
    "\n",
    "\n",
    "    # Define transforms\n",
    "    train_transforms = Compose([\n",
    "        ScaleIntensity(),\n",
    "        AddChannel(),\n",
    "        RandRotate(range_x=15.0, range_y=15.0, range_z=15.0, prob=0.5),\n",
    "        RandZoom(min_zoom=0.8, max_zoom=1.2, prob=0.5),\n",
    "        #SpatialPad((128, 128, 92), mode='constant'),\n",
    "        #Resize((128, 128, 92)),\n",
    "        ToTensor()\n",
    "    ])\n",
    "    \n",
    "    val_transforms = Compose([\n",
    "        ScaleIntensity(),\n",
    "        AddChannel(),\n",
    "        #SpatialPad((128, 128, 92), mode='constant'),\n",
    "        #Resize((128, 128, 92)),\n",
    "        ToTensor()\n",
    "    ])\n",
    "\n",
    "    # create a training data loader\n",
    "    train_ds = NiftiDataset(image_files=train_images, labels=train_labels, transform=train_transforms)\n",
    "    train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=2, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "    # create a validation data loader\n",
    "    val_ds = NiftiDataset(image_files=val_images, labels=val_labels, transform=val_transforms)\n",
    "    val_loader = DataLoader(val_ds, batch_size=2, num_workers=2, pin_memory=torch.cuda.is_available())\n",
    "    \n",
    "    device = torch.device('cuda:0')\n",
    "    model = densenet121(\n",
    "        spatial_dims=3,\n",
    "        in_channels=1,\n",
    "        out_channels=2,\n",
    "    ).to(device)\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), 1e-3)\n",
    "    \n",
    "    # finetuning\n",
    "    #model.load_state_dict(torch.load('best_metric_model_d121.pth'))\n",
    "\n",
    "    # start a typical PyTorch training\n",
    "    val_interval = 1\n",
    "    best_metric = -1\n",
    "    best_metric_epoch = -1\n",
    "    epoch_loss_values = list()\n",
    "    metric_values = list()\n",
    "    writer = SummaryWriter()\n",
    "    epc = 300 # Number of epoch\n",
    "    for epoch in range(epc):\n",
    "        print('-' * 10)\n",
    "        print('epoch {}/{}'.format(epoch + 1, epc))\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        step = 0\n",
    "        for batch_data in train_loader:\n",
    "            step += 1\n",
    "            inputs, labels = batch_data[0].to(device), batch_data[1].to(device=device, dtype=torch.int64)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_len = len(train_ds) // train_loader.batch_size\n",
    "            print('{}/{}, train_loss: {:.4f}'.format(step, epoch_len, loss.item()))\n",
    "            writer.add_scalar('train_loss', loss.item(), epoch_len * epoch + step)\n",
    "        epoch_loss /= step\n",
    "        epoch_loss_values.append(epoch_loss)\n",
    "        print('epoch {} average loss: {:.4f}'.format(epoch + 1, epoch_loss))\n",
    "\n",
    "        if (epoch + 1) % val_interval == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                num_correct = 0.\n",
    "                metric_count = 0\n",
    "                for val_data in val_loader:\n",
    "                    val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
    "                    val_outputs = model(val_images)\n",
    "                    value = torch.eq(val_outputs.argmax(dim=1), val_labels)\n",
    "                    metric_count += len(value)\n",
    "                    num_correct += value.sum().item()\n",
    "                metric = num_correct / metric_count\n",
    "                metric_values.append(metric)\n",
    "                #torch.save(model.state_dict(), 'model_d121_epoch_{}.pth'.format(epoch + 1))\n",
    "                if metric > best_metric:\n",
    "                    best_metric = metric\n",
    "                    best_metric_epoch = epoch + 1\n",
    "                    torch.save(model.state_dict(), '/home/marafath/scratch/saved_models/best_metric_model_d121_common_sized_no_avgpool.pth')\n",
    "                    print('saved new best metric model')\n",
    "                print('current epoch: {} current accuracy: {:.4f} best accuracy: {:.4f} at epoch {}'.format(\n",
    "                    epoch + 1, metric, best_metric, best_metric_epoch))\n",
    "                writer.add_scalar('val_accuracy', metric, epoch + 1)\n",
    "    print('train completed, best_metric: {:.4f} at epoch: {}'.format(best_metric, best_metric_epoch))\n",
    "    writer.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-27d7637d5f00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_images' is not defined"
     ]
    }
   ],
   "source": [
    "print(train_images[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
