{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This code works fine for Radiopedia 20 CT volumes with labels for Lung and Infections. The sbatch submission version is \"radiopedia_20_data.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 0.1.0+157.g7427173.dirty\n",
      "Python version: 3.7.4 (default, Jul 18 2019, 19:34:02)  [GCC 5.4.0]\n",
      "Numpy version: 1.18.1\n",
      "Pytorch version: 1.5.0\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.3.0\n",
      "Nibabel version: 3.1.0\n",
      "scikit-image version: 0.14.2\n",
      "Pillow version: 7.0.0\n",
      "Tensorboard version: 2.1.0\n",
      "MONAI version: 0.1.0+157.g7427173.dirty\n",
      "Python version: 3.7.4 (default, Jul 18 2019, 19:34:02)  [GCC 5.4.0]\n",
      "Numpy version: 1.18.1\n",
      "Pytorch version: 1.5.0\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.3.0\n",
      "Nibabel version: 3.1.0\n",
      "scikit-image version: 0.14.2\n",
      "Pillow version: 7.0.0\n",
      "Tensorboard version: 2.1.0\n",
      "----------\n",
      "epoch 1/100\n",
      "1/16, train_loss: 1.1407\n",
      "2/16, train_loss: 0.9697\n",
      "3/16, train_loss: 1.0346\n",
      "4/16, train_loss: 0.8635\n",
      "5/16, train_loss: 0.8732\n",
      "6/16, train_loss: 0.9480\n",
      "7/16, train_loss: 0.7842\n",
      "8/16, train_loss: 0.8864\n",
      "9/16, train_loss: 0.6771\n",
      "10/16, train_loss: 0.6077\n",
      "11/16, train_loss: 0.5084\n",
      "12/16, train_loss: 0.5370\n",
      "13/16, train_loss: 0.5471\n",
      "14/16, train_loss: 0.5273\n",
      "15/16, train_loss: 0.3779\n",
      "16/16, train_loss: 0.4717\n",
      "epoch 1 average loss: 0.7346\n",
      "saved new best metric model\n",
      "current epoch: 1 current mean dice: 0.4939 best mean dice: 0.4939 at epoch 1\n",
      "----------\n",
      "epoch 2/100\n",
      "1/16, train_loss: 0.5616\n",
      "2/16, train_loss: 0.4958\n",
      "3/16, train_loss: 0.5100\n",
      "4/16, train_loss: 0.5839\n",
      "5/16, train_loss: 0.4436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-49b9f40ba3db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-49b9f40ba3db>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ENV/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ENV/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "import shutil\n",
    "from glob import glob\n",
    "import logging\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import monai\n",
    "from monai.data import NiftiDataset, create_test_image_3d\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.metrics import compute_meandice\n",
    "from monai.visualize.img2tensorboard import plot_2d_or_3d_image\n",
    "from monai.transforms import \\\n",
    "    Compose, AddChannel, LoadNifti, \\\n",
    "    ScaleIntensity, RandSpatialCrop, \\\n",
    "    ToTensor, CastToType, SpatialPad\n",
    "\n",
    "monai.config.print_config()\n",
    "\n",
    "\n",
    "class CrossentropyND(torch.nn.CrossEntropyLoss):\n",
    "    \"\"\"\n",
    "    Network has to have NO NONLINEARITY!\n",
    "    \"\"\"\n",
    "    def forward(self, inp, target):\n",
    "        target = target.long()\n",
    "        num_classes = inp.size()[1]\n",
    "\n",
    "        i0 = 1\n",
    "        i1 = 2\n",
    "\n",
    "        while i1 < len(inp.shape): # this is ugly but torch only allows to transpose two axes at once\n",
    "            inp = inp.transpose(i0, i1)\n",
    "            i0 += 1\n",
    "            i1 += 1\n",
    "\n",
    "        inp = inp.contiguous()\n",
    "        inp = inp.view(-1, num_classes)\n",
    "\n",
    "        target = target.view(-1,)\n",
    "\n",
    "        return super(CrossentropyND, self).forward(inp, target)\n",
    "    \n",
    "class SoftDiceLoss(nn.Module):\n",
    "    def __init__(self, apply_nonlin=None, batch_dice=False, do_bg=True, smooth=1.):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super(SoftDiceLoss, self).__init__()\n",
    "\n",
    "        self.do_bg = do_bg\n",
    "        self.batch_dice = batch_dice\n",
    "        self.apply_nonlin = apply_nonlin\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, x, y, loss_mask=None):\n",
    "        shp_x = x.shape\n",
    "\n",
    "        if self.batch_dice:\n",
    "            axes = [0] + list(range(2, len(shp_x)))\n",
    "        else:\n",
    "            axes = list(range(2, len(shp_x)))\n",
    "\n",
    "        if self.apply_nonlin is not None:\n",
    "            x = self.apply_nonlin(x)\n",
    "\n",
    "        tp, fp, fn, _ = get_tp_fp_fn_tn(x, y, axes, loss_mask, False)\n",
    "\n",
    "        nominator = 2 * tp + self.smooth\n",
    "        denominator = 2 * tp + fp + fn + self.smooth\n",
    "\n",
    "        dc = nominator / denominator\n",
    "\n",
    "        if not self.do_bg:\n",
    "            if self.batch_dice:\n",
    "                dc = dc[1:]\n",
    "            else:\n",
    "                dc = dc[:, 1:]\n",
    "        dc = dc.mean()\n",
    "\n",
    "        return -dc\n",
    "    \n",
    "def get_tp_fp_fn_tn(net_output, gt, axes=None, mask=None, square=False):\n",
    "    \"\"\"\n",
    "    net_output must be (b, c, x, y(, z)))\n",
    "    gt must be a label map (shape (b, 1, x, y(, z)) OR shape (b, x, y(, z))) or one hot encoding (b, c, x, y(, z))\n",
    "    if mask is provided it must have shape (b, 1, x, y(, z)))\n",
    "    :param net_output:\n",
    "    :param gt:\n",
    "    :param axes: can be (, ) = no summation\n",
    "    :param mask: mask must be 1 for valid pixels and 0 for invalid pixels\n",
    "    :param square: if True then fp, tp and fn will be squared before summation\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if axes is None:\n",
    "        axes = tuple(range(2, len(net_output.size())))\n",
    "\n",
    "    shp_x = net_output.shape\n",
    "    shp_y = gt.shape\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if len(shp_x) != len(shp_y):\n",
    "            gt = gt.view((shp_y[0], 1, *shp_y[1:]))\n",
    "\n",
    "        if all([i == j for i, j in zip(net_output.shape, gt.shape)]):\n",
    "            # if this is the case then gt is probably already a one hot encoding\n",
    "            y_onehot = gt\n",
    "        else:\n",
    "            gt = gt.long()\n",
    "            y_onehot = torch.zeros(shp_x)\n",
    "            if net_output.device.type == \"cuda\":\n",
    "                y_onehot = y_onehot.cuda(net_output.device.index)\n",
    "            y_onehot.scatter_(1, gt, 1)\n",
    "\n",
    "    tp = net_output * y_onehot\n",
    "    fp = net_output * (1 - y_onehot)\n",
    "    fn = (1 - net_output) * y_onehot\n",
    "    tn = (1 - net_output) * (1 - y_onehot)\n",
    "\n",
    "    if mask is not None:\n",
    "        tp = torch.stack(tuple(x_i * mask[:, 0] for x_i in torch.unbind(tp, dim=1)), dim=1)\n",
    "        fp = torch.stack(tuple(x_i * mask[:, 0] for x_i in torch.unbind(fp, dim=1)), dim=1)\n",
    "        fn = torch.stack(tuple(x_i * mask[:, 0] for x_i in torch.unbind(fn, dim=1)), dim=1)\n",
    "        tn = torch.stack(tuple(x_i * mask[:, 0] for x_i in torch.unbind(tn, dim=1)), dim=1)\n",
    "\n",
    "    if square:\n",
    "        tp = tp ** 2\n",
    "        fp = fp ** 2\n",
    "        fn = fn ** 2\n",
    "        tn = tn ** 2\n",
    "\n",
    "    if len(axes) > 0:\n",
    "        tp = sum_tensor(tp, axes, keepdim=False)\n",
    "        fp = sum_tensor(fp, axes, keepdim=False)\n",
    "        fn = sum_tensor(fn, axes, keepdim=False)\n",
    "        tn = sum_tensor(tn, axes, keepdim=False)\n",
    "\n",
    "    return tp, fp, fn, tn\n",
    "\n",
    "class DC_and_CE_loss(nn.Module):\n",
    "    def __init__(self, soft_dice_kwargs, ce_kwargs, aggregate=\"sum\", square_dice=False, weight_ce=1, weight_dice=1):\n",
    "        \"\"\"\n",
    "        CAREFUL. Weights for CE and Dice do not need to sum to one. You can set whatever you want.\n",
    "        :param soft_dice_kwargs:\n",
    "        :param ce_kwargs:\n",
    "        :param aggregate:\n",
    "        :param square_dice:\n",
    "        :param weight_ce:\n",
    "        :param weight_dice:\n",
    "        \"\"\"\n",
    "        super(DC_and_CE_loss, self).__init__()\n",
    "        self.weight_dice = weight_dice\n",
    "        self.weight_ce = weight_ce\n",
    "        self.aggregate = aggregate\n",
    "        self.ce = CrossentropyND(**ce_kwargs)\n",
    "        self.dc = SoftDiceLoss(apply_nonlin=softmax_helper, **soft_dice_kwargs)\n",
    "\n",
    "    def forward(self, net_output, target):\n",
    "        dc_loss = self.dc(net_output, target) if self.weight_dice != 0 else 0\n",
    "        ce_loss = self.ce(net_output, target) if self.weight_ce != 0 else 0\n",
    "        if self.aggregate == \"sum\":\n",
    "            result = self.weight_ce * ce_loss + self.weight_dice * dc_loss\n",
    "        else:\n",
    "            raise NotImplementedError(\"nah son\") # reserved for other stuff (later)\n",
    "        return result\n",
    "\n",
    "def softmax_helper(x):\n",
    "    rpt = [1 for _ in range(len(x.size()))]\n",
    "    rpt[1] = x.size(1)\n",
    "    x_max = x.max(1, keepdim=True)[0].repeat(*rpt)\n",
    "    e_x = torch.exp(x - x_max)\n",
    "    return e_x / e_x.sum(1, keepdim=True).repeat(*rpt)\n",
    "\n",
    "def sum_tensor(inp, axes, keepdim=False):\n",
    "    axes = np.unique(axes).astype(int)\n",
    "    if keepdim:\n",
    "        for ax in axes:\n",
    "            inp = inp.sum(int(ax), keepdim=True)\n",
    "    else:\n",
    "        for ax in sorted(axes, reverse=True):\n",
    "            inp = inp.sum(int(ax))\n",
    "    return inp\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    monai.config.print_config()\n",
    "    logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "\n",
    "    # Supervised learning data for training and validation\n",
    "    data_dir = '/home/marafath/scratch/3d_seg_ct'\n",
    "    fold = 5\n",
    "    epc = 100\n",
    "    \n",
    "    for i in range(0,fold):\n",
    "        train_images = []\n",
    "        train_labels = []\n",
    "\n",
    "        val_images = []\n",
    "        val_labels = []\n",
    "        for case in os.listdir(data_dir): \n",
    "            if i == 0:\n",
    "                if int(case[2:4]) > 16:\n",
    "                    train_images.append(os.path.join(data_dir,case,'image.nii.gz'))\n",
    "                    train_labels.append(os.path.join(data_dir,case,'label.nii.gz'))\n",
    "                else:\n",
    "                    val_images.append(os.path.join(data_dir,case,'image.nii.gz'))\n",
    "                    val_labels.append(os.path.join(data_dir,case,'label.nii.gz'))\n",
    "            elif i == 1:\n",
    "                if int(case[2:4]) < 17 or int(case[2:4]) > 32:\n",
    "                    train_images.append(os.path.join(data_dir,case,'image.nii.gz'))\n",
    "                    train_labels.append(os.path.join(data_dir,case,'label.nii.gz'))\n",
    "                else:\n",
    "                    val_images.append(os.path.join(data_dir,case,'image.nii.gz'))\n",
    "                    val_labels.append(os.path.join(data_dir,case,'label.nii.gz'))\n",
    "            elif i == 2:\n",
    "                if int(case[2:4]) < 33 or int(case[2:4]) > 48:\n",
    "                    train_images.append(os.path.join(data_dir,case,'image.nii.gz'))\n",
    "                    train_labels.append(os.path.join(data_dir,case,'label.nii.gz'))\n",
    "                else:\n",
    "                    val_images.append(os.path.join(data_dir,case,'image.nii.gz'))\n",
    "                    val_labels.append(os.path.join(data_dir,case,'label.nii.gz'))\n",
    "            elif i == 3:\n",
    "                if int(case[2:4]) < 49 or int(case[2:4]) > 64:\n",
    "                    train_images.append(os.path.join(data_dir,case,'image.nii.gz'))\n",
    "                    train_labels.append(os.path.join(data_dir,case,'label.nii.gz'))\n",
    "                else:\n",
    "                    val_images.append(os.path.join(data_dir,case,'image.nii.gz'))\n",
    "                    val_labels.append(os.path.join(data_dir,case,'label.nii.gz'))\n",
    "            elif i == 4:\n",
    "                if int(case[2:4]) < 65:\n",
    "                    train_images.append(os.path.join(data_dir,case,'image.nii.gz'))\n",
    "                    train_labels.append(os.path.join(data_dir,case,'label.nii.gz'))\n",
    "                else:\n",
    "                    val_images.append(os.path.join(data_dir,case,'image.nii.gz'))\n",
    "                    val_labels.append(os.path.join(data_dir,case,'label.nii.gz'))\n",
    "\n",
    "        # Defining Transform\n",
    "        train_imtrans = Compose([\n",
    "            ScaleIntensity(),\n",
    "            AddChannel(),\n",
    "            CastToType(), #default is `np.float32`\n",
    "            RandSpatialCrop((96, 96, 96), random_size=False),\n",
    "            SpatialPad((96, 96, 96), mode='constant'),\n",
    "            ToTensor()\n",
    "        ])\n",
    "        train_segtrans = Compose([\n",
    "            AddChannel(),\n",
    "            CastToType(), #default is `np.float32`\n",
    "            RandSpatialCrop((96, 96, 96), random_size=False),\n",
    "            SpatialPad((96, 96, 96), mode='constant'),\n",
    "            ToTensor()\n",
    "        ])\n",
    "        val_imtrans = Compose([\n",
    "            ScaleIntensity(),\n",
    "            AddChannel(),\n",
    "            CastToType(),\n",
    "            SpatialPad((96, 96, 96), mode='constant'),\n",
    "            ToTensor()\n",
    "        ])\n",
    "        val_segtrans = Compose([\n",
    "            AddChannel(),\n",
    "            CastToType(),\n",
    "            SpatialPad((96, 96, 96), mode='constant'),\n",
    "            ToTensor()\n",
    "        ])\n",
    "\n",
    "        # create a training data loader\n",
    "        train_ds = NiftiDataset(train_images, train_labels, transform=train_imtrans, seg_transform=train_segtrans)\n",
    "        train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=8, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "        # create a validation data loader\n",
    "        val_ds = NiftiDataset(val_images, val_labels, transform=val_imtrans, seg_transform=val_segtrans)\n",
    "        val_loader = DataLoader(val_ds, batch_size=1, num_workers=4, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "        # Defining model and hyperparameters\n",
    "        device = torch.device('cuda:0')\n",
    "        model = monai.networks.nets.UNet(\n",
    "            dimensions=3,\n",
    "            in_channels=1,\n",
    "            out_channels=3,\n",
    "            channels=(16, 32, 64, 128, 256),\n",
    "            strides=(2, 2, 2, 2),\n",
    "            num_res_units=2,\n",
    "        ).to(device)\n",
    "\n",
    "        loss_function = DC_and_CE_loss({'smooth': 1e-5, 'do_bg': False}, {})\n",
    "        optimizer = torch.optim.Adam(model.parameters(), 1e-3)\n",
    "\n",
    "        # start a typical PyTorch training\n",
    "        val_interval = 1\n",
    "        best_metric = -1\n",
    "        best_metric_epoch = -1\n",
    "        epoch_loss_values = list()\n",
    "        metric_values = list()\n",
    "        writer = SummaryWriter()\n",
    "        for epoch in range(epc):\n",
    "            print('-' * 10)\n",
    "            print('epoch {}/{}'.format(epoch + 1, epc))\n",
    "            model.train()\n",
    "            epoch_loss = 0\n",
    "            step = 0\n",
    "            for batch_data in train_loader:\n",
    "                step += 1\n",
    "                inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = loss_function(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss.item()\n",
    "                epoch_len = len(train_ds) // train_loader.batch_size\n",
    "                # print('{}/{}, train_loss: {:.4f}'.format(step, epoch_len, loss.item()))\n",
    "                writer.add_scalar('train_loss', loss.item(), epoch_len * epoch + step)\n",
    "            epoch_loss /= step\n",
    "            epoch_loss_values.append(epoch_loss)\n",
    "            print('epoch {} average loss: {:.4f}'.format(epoch + 1, epoch_loss))\n",
    "\n",
    "            if (epoch + 1) % val_interval == 0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    metric_sum = 0.\n",
    "                    metric_count = 0\n",
    "                    val_images_ = None\n",
    "                    val_labels_ = None\n",
    "                    val_outputs = None\n",
    "                    for val_data in val_loader:\n",
    "                        val_images_, val_labels_ = val_data[0].to(device), val_data[1].to(device)\n",
    "                        roi_size = (160, 160, 96)\n",
    "                        sw_batch_size = 4\n",
    "                        val_outputs = sliding_window_inference(val_images_, roi_size, sw_batch_size, model)\n",
    "                        value = compute_meandice(y_pred=val_outputs, y=val_labels_, include_background=False,\n",
    "                                         to_onehot_y=True, sigmoid=False, mutually_exclusive=True)\n",
    "                        metric_count += len(value)\n",
    "                        metric_sum += value.sum().item()\n",
    "                    metric = metric_sum / metric_count\n",
    "                    metric_values.append(metric)\n",
    "                    if metric > best_metric:\n",
    "                        best_metric = metric\n",
    "                        best_metric_epoch = epoch + 1\n",
    "                        torch.save(model.state_dict(), '/home/marafath/scratch/saved_models/UNet3D_radiopedia_best_metric_model_dice_fold{}.pth'.format(i))\n",
    "                        print(\"saved new best metric model\")\n",
    "                    print(\n",
    "                    \"current epoch: {} current mean dice: {:.4f} best mean dice: {:.4f} at epoch {}\".format(\n",
    "                        epoch + 1, metric, best_metric, best_metric_epoch\n",
    "                    )\n",
    "                )\n",
    "                    # plot the last model output as GIF image in TensorBoard with the corresponding image and label\n",
    "                    plot_2d_or_3d_image(val_images_, epoch + 1, writer, index=0, tag='image')\n",
    "                    plot_2d_or_3d_image(val_labels_, epoch + 1, writer, index=0, tag='label')\n",
    "                    plot_2d_or_3d_image(val_outputs, epoch + 1, writer, index=0, tag='output')\n",
    "\n",
    "        print('train completed, best_metric: {:.4f} at epoch: {}'.format(best_metric, best_metric_epoch))\n",
    "        writer.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
