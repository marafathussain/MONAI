{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import Callable, Sequence\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import sys\n",
    "import logging\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import monai\n",
    "from monai.data import NiftiDataset\n",
    "from monai.transforms import Compose, Spacing, SpatialPad, AddChannel, ScaleIntensity, Resize, RandRotate90, RandRotate, RandZoom, ToTensor\n",
    "import os\n",
    "\n",
    "from monai.networks.layers.factories import Conv, Dropout, Pool, Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _DenseLayer(nn.Sequential):\n",
    "    def __init__(\n",
    "        self, spatial_dims: int, in_channels: int, growth_rate: int, bn_size: int, dropout_prob: float\n",
    "    ) -> None:\n",
    "        super(_DenseLayer, self).__init__()\n",
    "\n",
    "        out_channels = bn_size * growth_rate\n",
    "        conv_type: Callable = Conv[Conv.CONV, spatial_dims]\n",
    "        norm_type: Callable = Norm[Norm.BATCH, spatial_dims]\n",
    "        dropout_type: Callable = Dropout[Dropout.DROPOUT, spatial_dims]\n",
    "\n",
    "        self.add_module(\"norm1\", norm_type(in_channels))\n",
    "        self.add_module(\"relu1\", nn.ReLU(inplace=True))\n",
    "        self.add_module(\"conv1\", conv_type(in_channels, out_channels, kernel_size=1, bias=False))\n",
    "\n",
    "        self.add_module(\"norm2\", norm_type(out_channels))\n",
    "        self.add_module(\"relu2\", nn.ReLU(inplace=True))\n",
    "        self.add_module(\"conv2\", conv_type(out_channels, growth_rate, kernel_size=3, padding=1, bias=False))\n",
    "\n",
    "        if dropout_prob > 0:\n",
    "            self.add_module(\"dropout\", dropout_type(dropout_prob))\n",
    "\n",
    "    def forward(self, x):\n",
    "        new_features = super(_DenseLayer, self).forward(x)\n",
    "        return torch.cat([x, new_features], 1)\n",
    "\n",
    "\n",
    "class _DenseBlock(nn.Sequential):\n",
    "    def __init__(\n",
    "        self, spatial_dims: int, layers: int, in_channels: int, bn_size: int, growth_rate: int, dropout_prob: float\n",
    "    ) -> None:\n",
    "        super(_DenseBlock, self).__init__()\n",
    "        for i in range(layers):\n",
    "            layer = _DenseLayer(spatial_dims, in_channels, growth_rate, bn_size, dropout_prob)\n",
    "            in_channels += growth_rate\n",
    "            self.add_module(\"denselayer%d\" % (i + 1), layer)\n",
    "\n",
    "\n",
    "class _Transition(nn.Sequential):\n",
    "    def __init__(self, spatial_dims: int, in_channels: int, out_channels: int) -> None:\n",
    "        super(_Transition, self).__init__()\n",
    "\n",
    "        conv_type: Callable = Conv[Conv.CONV, spatial_dims]\n",
    "        norm_type: Callable = Norm[Norm.BATCH, spatial_dims]\n",
    "        pool_type: Callable = Pool[Pool.AVG, spatial_dims]\n",
    "\n",
    "        self.add_module(\"norm\", norm_type(in_channels))\n",
    "        self.add_module(\"relu\", nn.ReLU(inplace=True))\n",
    "        self.add_module(\"conv\", conv_type(in_channels, out_channels, kernel_size=1, bias=False))\n",
    "        self.add_module(\"pool\", pool_type(kernel_size=2, stride=2))\n",
    "\n",
    "\n",
    "class DenseNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Densenet based on: \"Densely Connected Convolutional Networks\" https://arxiv.org/pdf/1608.06993.pdf\n",
    "    Adapted from PyTorch Hub 2D version:\n",
    "    https://github.com/pytorch/vision/blob/master/torchvision/models/densenet.py\n",
    "\n",
    "    Args:\n",
    "        spatial_dims: number of spatial dimensions of the input image.\n",
    "        in_channels: number of the input channel.\n",
    "        out_channels: number of the output classes.\n",
    "        init_features: number of filters in the first convolution layer.\n",
    "        growth_rate: how many filters to add each layer (k in paper).\n",
    "        block_config: how many layers in each pooling block.\n",
    "        bn_size: multiplicative factor for number of bottle neck layers.\n",
    "                      (i.e. bn_size * k features in the bottleneck layer)\n",
    "        dropout_prob: dropout rate after each dense layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        spatial_dims: int,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        init_features: int = 64,\n",
    "        growth_rate: int = 32,\n",
    "        block_config: Sequence[int] = (6, 12, 24, 16),\n",
    "        bn_size: int = 4,\n",
    "        dropout_prob: float = 0.0,\n",
    "        bins=8,\n",
    "        pool_kernel=32,\n",
    "        pool_stride=32\n",
    "    ) -> None:\n",
    "\n",
    "        super(DenseNet, self).__init__()\n",
    "\n",
    "        conv_type: Callable = Conv[Conv.CONV, spatial_dims]\n",
    "        norm_type: Callable = Norm[Norm.BATCH, spatial_dims]\n",
    "        pool_type: Callable = Pool[Pool.MAX, spatial_dims]\n",
    "        avg_pool_type: Callable = Pool[Pool.ADAPTIVEAVG, spatial_dims]\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\"conv0\", conv_type(in_channels, init_features, kernel_size=7, stride=2, padding=3, bias=False)),\n",
    "                    (\"norm0\", norm_type(init_features)),\n",
    "                    (\"relu0\", nn.ReLU(inplace=True)),\n",
    "                    (\"pool0\", pool_type(kernel_size=3, stride=2, padding=1)),\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        in_channels = init_features\n",
    "        for i, num_layers in enumerate(block_config):\n",
    "            block = _DenseBlock(\n",
    "                spatial_dims=spatial_dims,\n",
    "                layers=num_layers,\n",
    "                in_channels=in_channels,\n",
    "                bn_size=bn_size,\n",
    "                growth_rate=growth_rate,\n",
    "                dropout_prob=dropout_prob,\n",
    "            )\n",
    "            self.features.add_module(\"denseblock%d\" % (i + 1), block)\n",
    "            in_channels += num_layers * growth_rate\n",
    "            if i == len(block_config) - 1:\n",
    "                self.features.add_module(\"norm5\", norm_type(in_channels))\n",
    "            else:\n",
    "                _out_channels = in_channels // 2\n",
    "                trans = _Transition(spatial_dims, in_channels=in_channels, out_channels=_out_channels)\n",
    "                self.features.add_module(\"transition%d\" % (i + 1), trans)\n",
    "                in_channels = _out_channels\n",
    "\n",
    "        # pooling and classification\n",
    "        '''\n",
    "        self.class_layers = nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\"relu\", nn.ReLU(inplace=True)),\n",
    "                    (\"norm\", avg_pool_type(1)),\n",
    "                    (\"flatten\", nn.Flatten(1)), \n",
    "                    (\"class\", nn.Linear(in_channels, out_channels)),\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        '''\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc1 = nn.Linear(1024*4*4*4, 1024)\n",
    "        self.fc2 = nn.Linear(2048, out_channels)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, conv_type):  # type: ignore\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, norm_type):  # type: ignore\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "        # 3D-ImHistNet\n",
    "        self.conv1 = nn.Conv3d(1, bins, 1, 1)\n",
    "        nn.init.constant_(self.conv1.weight, 1.0)\n",
    "        \n",
    "        \n",
    "        self.conv2 = nn.Conv3d(bins, bins, 1, 1, groups=bins)\n",
    "        nn.init.constant_(self.conv2.bias, 1.0)\n",
    "    \n",
    "        self.avgpool = nn.AvgPool3d(pool_kernel, pool_stride)\n",
    "        self.hist_fc = nn.Linear(bins*4*4*4, 1024)\n",
    "        #self.fc2 = nn.Linear(1024, no_classes)\n",
    "\n",
    "        #initialize_params(self)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.features(x)\n",
    "        x1 = torch.flatten(x1, 1)\n",
    "        x1 = self.fc1(x1)\n",
    "        \n",
    "        x2 = self.conv1(x)\n",
    "        x2 = torch.abs(x2)\n",
    "        x2 = self.conv2(x2)\n",
    "        x2 = self.relu(x2)\n",
    "        x2 = self.avgpool(x2)\n",
    "        x2 = torch.flatten(x2, 1)\n",
    "        x2 = self.hist_fc(x2)\n",
    "        \n",
    "        x_cat = torch.cat([x1, x2], 1)\n",
    "        x_cat = self.fc2(x_cat)\n",
    "        return x_cat\n",
    "\n",
    "\n",
    "def densenet121(**kwargs) -> DenseNet:\n",
    "    model = DenseNet(init_features=64, growth_rate=32, block_config=(6, 12, 24, 16), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def densenet169(**kwargs) -> DenseNet:\n",
    "    model = DenseNet(init_features=64, growth_rate=32, block_config=(6, 12, 32, 32), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def densenet201(**kwargs) -> DenseNet:\n",
    "    model = DenseNet(init_features=64, growth_rate=32, block_config=(6, 12, 48, 32), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def densenet264(**kwargs) -> DenseNet:\n",
    "    model = DenseNet(init_features=64, growth_rate=32, block_config=(6, 12, 64, 48), **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corona+ patient 223\n",
      "Corona- patient 399\n"
     ]
    }
   ],
   "source": [
    "# Training data paths\n",
    "data_dir = '/home/marafath/scratch/iran_organized_data2'\n",
    "\n",
    "covid_pat = 0\n",
    "non_covid_pat = 0\n",
    "\n",
    "pos_pat = []\n",
    "neg_pat = []\n",
    "\n",
    "for patient in os.listdir(data_dir):\n",
    "    if int(patient[-1]) == 1:\n",
    "        covid_pat += 1\n",
    "        pos_pat.append(os.path.join(data_dir,patient))\n",
    "    else:\n",
    "        non_covid_pat += 1\n",
    "        neg_pat.append(os.path.join(data_dir,patient))\n",
    "        \n",
    "print('Corona+ patient {}'.format(covid_pat))\n",
    "print('Corona- patient {}'.format(non_covid_pat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corona+ patient 55\n",
      "Corona- patient 99\n"
     ]
    }
   ],
   "source": [
    "# 4-fold cross-validation\n",
    "import math\n",
    "\n",
    "pos_val = math.floor(covid_pat/4)\n",
    "neg_val = math.floor(non_covid_pat/4)\n",
    "\n",
    "print('Corona+ patient {}'.format(pos_val))\n",
    "print('Corona- patient {}'.format(neg_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data paths\n",
    "fold = 4\n",
    "\n",
    "for i in range(0,4): # i = current fold\n",
    "    p_strt = pos_val*i + 1\n",
    "    p_end = pos_val*i + pos_val\n",
    "    n_strt = p_strt\n",
    "    n_end = p_end\n",
    "    \n",
    "    pos_resample_rate = math.floor((len(neg_pat)-pos_val)/(len(pos_pat)-pos_val))\n",
    "    \n",
    "    val_image = []\n",
    "    val_label = []\n",
    "    trn_image = []\n",
    "    trn_label = []\n",
    "        \n",
    "    for j, pat_link in enumerate(pos_pat): \n",
    "        if j >= p_strt and j < p_end:\n",
    "            for series in os.listdir(pat_link):\n",
    "                val_label.append(1)\n",
    "                val_image.append(os.path.join(pat_link,series,'cropped_and_resized_image.nii.gz'))\n",
    "                break\n",
    "        else:\n",
    "            for series in os.listdir(pat_link):\n",
    "                for rs in range(0, pos_resample_rate):\n",
    "                    trn_label.append(1)\n",
    "                    trn_image.append(os.path.join(pat_link,series,'cropped_and_resized_image.nii.gz'))\n",
    "        \n",
    "    for k, pat_link in enumerate(neg_pat): \n",
    "        if k >= n_strt and k < n_end:\n",
    "            for series in os.listdir(pat_link):\n",
    "                val_label.append(0)\n",
    "                val_image.append(os.path.join(pat_link,series,'cropped_and_resized_image.nii.gz'))\n",
    "                break\n",
    "        else:\n",
    "            for series in os.listdir(pat_link):\n",
    "                trn_label.append(0)\n",
    "                trn_image.append(os.path.join(pat_link,series,'cropped_and_resized_image.nii.gz'))\n",
    "    break  \n",
    "\n",
    "trn_label = np.asarray(trn_label,np.int64)\n",
    "val_label = np.asarray(val_label,np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train scans 1468\n",
      "val scans 103\n"
     ]
    }
   ],
   "source": [
    "print('train scans {}'.format(len(trn_label)))\n",
    "print('val scans {}'.format(len(val_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('pos_train scans {}'.format(np.sum(trn_label)))\n",
    "print('pos_val scans {}'.format(np.sum(val_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms\n",
    "train_transforms = Compose([\n",
    "    ScaleIntensity(),\n",
    "    AddChannel(),\n",
    "    RandRotate(range_x=10.0, range_y=10.0, range_z=10.0, prob=0.5),\n",
    "    RandZoom(min_zoom=0.9, max_zoom=1.1, prob=0.5),\n",
    "    #Spacing(pixdim=(2.0,2.0,2.0),mode='bilinear'),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "val_transforms = Compose([\n",
    "    ScaleIntensity(),\n",
    "    AddChannel(),\n",
    "    #Spacing(pixdim=(2.0,2.0,2.0),mode='bilinear'),\n",
    "    ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([2, 1, 128, 128, 128]) tensor([1, 1])\n"
     ]
    }
   ],
   "source": [
    "check_ds = NiftiDataset(image_files=trn_image, labels=trn_label, transform=train_transforms)\n",
    "check_loader = DataLoader(check_ds, batch_size=2, num_workers=2, pin_memory=torch.cuda.is_available())\n",
    "im, label = monai.utils.misc.first(check_loader)\n",
    "print(type(im), im.shape, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a training data loader\n",
    "train_ds = NiftiDataset(image_files=trn_image, labels=trn_label, transform=train_transforms)\n",
    "train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=2, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "# create a validation data loader\n",
    "val_ds = NiftiDataset(image_files=val_image, labels=val_label, transform=val_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size=2, num_workers=2, pin_memory=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "model = densenet121(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=2,\n",
    ").to(device)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('/home/marafath/scratch/saved_models/best_test.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "epoch 1/300\n",
      "1/734, train_loss: 0.3683\n",
      "2/734, train_loss: 0.3260\n",
      "3/734, train_loss: 0.3296\n",
      "4/734, train_loss: 0.4846\n",
      "5/734, train_loss: 0.1345\n",
      "saved new best metric model\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "6/734, train_loss: 0.2691\n",
      "7/734, train_loss: 0.7893\n",
      "8/734, train_loss: 1.3630\n",
      "9/734, train_loss: 0.5123\n",
      "10/734, train_loss: 0.7170\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "11/734, train_loss: 1.2071\n",
      "12/734, train_loss: 0.4477\n",
      "13/734, train_loss: 0.1638\n",
      "14/734, train_loss: 0.5658\n",
      "15/734, train_loss: 0.5789\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "16/734, train_loss: 0.2418\n",
      "17/734, train_loss: 1.0758\n",
      "18/734, train_loss: 0.4993\n",
      "19/734, train_loss: 0.4664\n",
      "20/734, train_loss: 0.9071\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "21/734, train_loss: 0.3396\n",
      "22/734, train_loss: 0.4855\n",
      "23/734, train_loss: 0.2296\n",
      "24/734, train_loss: 0.1677\n",
      "25/734, train_loss: 0.3445\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "26/734, train_loss: 0.3977\n",
      "27/734, train_loss: 0.2929\n",
      "28/734, train_loss: 0.5001\n",
      "29/734, train_loss: 0.6164\n",
      "30/734, train_loss: 0.3906\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "31/734, train_loss: 0.7980\n",
      "32/734, train_loss: 0.7519\n",
      "33/734, train_loss: 0.9200\n",
      "34/734, train_loss: 0.6791\n",
      "35/734, train_loss: 0.4848\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "36/734, train_loss: 0.3625\n",
      "37/734, train_loss: 0.2275\n",
      "38/734, train_loss: 0.5152\n",
      "39/734, train_loss: 0.9537\n",
      "40/734, train_loss: 0.1752\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "41/734, train_loss: 0.7321\n",
      "42/734, train_loss: 0.7397\n",
      "43/734, train_loss: 0.6029\n",
      "44/734, train_loss: 0.9030\n",
      "45/734, train_loss: 0.1457\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "46/734, train_loss: 0.8025\n",
      "47/734, train_loss: 0.3676\n",
      "48/734, train_loss: 0.9163\n",
      "49/734, train_loss: 0.7923\n",
      "50/734, train_loss: 0.5042\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "51/734, train_loss: 1.0205\n",
      "52/734, train_loss: 0.4818\n",
      "53/734, train_loss: 0.8611\n",
      "54/734, train_loss: 0.8786\n",
      "55/734, train_loss: 0.4926\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "56/734, train_loss: 0.6674\n",
      "57/734, train_loss: 0.8310\n",
      "58/734, train_loss: 0.3194\n",
      "59/734, train_loss: 1.1351\n",
      "60/734, train_loss: 1.3904\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "61/734, train_loss: 0.6113\n",
      "62/734, train_loss: 0.4233\n",
      "63/734, train_loss: 0.9557\n",
      "64/734, train_loss: 0.1167\n",
      "65/734, train_loss: 0.6792\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "66/734, train_loss: 0.6931\n",
      "67/734, train_loss: 0.8416\n",
      "68/734, train_loss: 0.5370\n",
      "69/734, train_loss: 0.2356\n",
      "70/734, train_loss: 0.5726\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "71/734, train_loss: 0.2520\n",
      "72/734, train_loss: 0.1465\n",
      "73/734, train_loss: 0.2522\n",
      "74/734, train_loss: 0.3138\n",
      "75/734, train_loss: 0.5406\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "76/734, train_loss: 0.4461\n",
      "77/734, train_loss: 0.5254\n",
      "78/734, train_loss: 0.6806\n",
      "79/734, train_loss: 0.4479\n",
      "80/734, train_loss: 0.9265\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "81/734, train_loss: 0.7280\n",
      "82/734, train_loss: 0.4887\n",
      "83/734, train_loss: 0.1579\n",
      "84/734, train_loss: 0.2978\n",
      "85/734, train_loss: 0.3856\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "86/734, train_loss: 0.9021\n",
      "87/734, train_loss: 0.5328\n",
      "88/734, train_loss: 0.6838\n",
      "89/734, train_loss: 0.9563\n",
      "90/734, train_loss: 0.6842\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "91/734, train_loss: 0.3105\n",
      "92/734, train_loss: 0.4273\n",
      "93/734, train_loss: 0.6511\n",
      "94/734, train_loss: 0.4365\n",
      "95/734, train_loss: 0.7841\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "96/734, train_loss: 0.6280\n",
      "97/734, train_loss: 0.6870\n",
      "98/734, train_loss: 0.4706\n",
      "99/734, train_loss: 0.3028\n",
      "100/734, train_loss: 0.7130\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "101/734, train_loss: 1.0395\n",
      "102/734, train_loss: 0.4335\n",
      "103/734, train_loss: 0.5993\n",
      "104/734, train_loss: 0.0227\n",
      "105/734, train_loss: 0.3386\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "106/734, train_loss: 0.8100\n",
      "107/734, train_loss: 0.4739\n",
      "108/734, train_loss: 0.8576\n",
      "109/734, train_loss: 0.7860\n",
      "110/734, train_loss: 0.6773\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "111/734, train_loss: 1.1711\n",
      "112/734, train_loss: 0.6775\n",
      "113/734, train_loss: 0.7749\n",
      "114/734, train_loss: 0.2867\n",
      "115/734, train_loss: 0.6195\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "116/734, train_loss: 0.5868\n",
      "117/734, train_loss: 0.1374\n",
      "118/734, train_loss: 0.1689\n",
      "119/734, train_loss: 0.5145\n",
      "120/734, train_loss: 0.1491\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "121/734, train_loss: 0.2753\n",
      "122/734, train_loss: 0.4347\n",
      "123/734, train_loss: 0.8983\n",
      "124/734, train_loss: 0.6233\n",
      "125/734, train_loss: 0.4075\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "126/734, train_loss: 0.6693\n",
      "127/734, train_loss: 0.4174\n",
      "128/734, train_loss: 0.4632\n",
      "129/734, train_loss: 0.5313\n",
      "130/734, train_loss: 0.6596\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "131/734, train_loss: 0.3952\n",
      "132/734, train_loss: 0.3122\n",
      "133/734, train_loss: 0.5781\n",
      "134/734, train_loss: 0.6958\n",
      "135/734, train_loss: 0.8312\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "136/734, train_loss: 0.2811\n",
      "137/734, train_loss: 0.8877\n",
      "138/734, train_loss: 0.4785\n",
      "139/734, train_loss: 0.4409\n",
      "140/734, train_loss: 0.4751\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "141/734, train_loss: 0.4683\n",
      "142/734, train_loss: 0.6873\n",
      "143/734, train_loss: 0.4809\n",
      "144/734, train_loss: 0.2224\n",
      "145/734, train_loss: 1.5068\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "146/734, train_loss: 0.5996\n",
      "147/734, train_loss: 0.3762\n",
      "148/734, train_loss: 0.6721\n",
      "149/734, train_loss: 0.4266\n",
      "150/734, train_loss: 0.2744\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "151/734, train_loss: 0.6583\n",
      "152/734, train_loss: 0.4778\n",
      "153/734, train_loss: 0.6675\n",
      "154/734, train_loss: 1.4238\n",
      "155/734, train_loss: 0.5538\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "156/734, train_loss: 0.3728\n",
      "157/734, train_loss: 0.2305\n",
      "158/734, train_loss: 0.6735\n",
      "159/734, train_loss: 0.4137\n",
      "160/734, train_loss: 0.6927\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "161/734, train_loss: 0.6235\n",
      "162/734, train_loss: 0.2070\n",
      "163/734, train_loss: 0.3556\n",
      "164/734, train_loss: 0.3914\n",
      "165/734, train_loss: 0.7752\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "166/734, train_loss: 0.3776\n",
      "167/734, train_loss: 0.5205\n",
      "168/734, train_loss: 0.6851\n",
      "169/734, train_loss: 0.4020\n",
      "170/734, train_loss: 0.6678\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "171/734, train_loss: 0.9084\n",
      "172/734, train_loss: 0.3239\n",
      "173/734, train_loss: 0.4984\n",
      "174/734, train_loss: 0.8025\n",
      "175/734, train_loss: 0.2865\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "176/734, train_loss: 0.2527\n",
      "177/734, train_loss: 0.1820\n",
      "178/734, train_loss: 1.5187\n",
      "179/734, train_loss: 0.1600\n",
      "180/734, train_loss: 0.2344\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "181/734, train_loss: 0.5552\n",
      "182/734, train_loss: 0.3409\n",
      "183/734, train_loss: 0.2455\n",
      "184/734, train_loss: 0.7737\n",
      "185/734, train_loss: 0.6719\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "186/734, train_loss: 0.5734\n",
      "187/734, train_loss: 0.3601\n",
      "188/734, train_loss: 0.6322\n",
      "189/734, train_loss: 0.5907\n",
      "190/734, train_loss: 0.9392\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "191/734, train_loss: 0.3555\n",
      "192/734, train_loss: 0.6387\n",
      "193/734, train_loss: 0.4148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194/734, train_loss: 0.8075\n",
      "195/734, train_loss: 0.3475\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "196/734, train_loss: 0.1883\n",
      "197/734, train_loss: 0.4717\n",
      "198/734, train_loss: 1.1180\n",
      "199/734, train_loss: 1.1304\n",
      "200/734, train_loss: 0.4354\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "201/734, train_loss: 0.7474\n",
      "202/734, train_loss: 0.8342\n",
      "203/734, train_loss: 0.4091\n",
      "204/734, train_loss: 0.6441\n",
      "205/734, train_loss: 1.0549\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "206/734, train_loss: 0.3707\n",
      "207/734, train_loss: 0.1371\n",
      "208/734, train_loss: 0.3908\n",
      "209/734, train_loss: 0.6686\n",
      "210/734, train_loss: 0.7353\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "211/734, train_loss: 0.7794\n",
      "212/734, train_loss: 0.6235\n",
      "213/734, train_loss: 0.2947\n",
      "214/734, train_loss: 0.3047\n",
      "215/734, train_loss: 0.5717\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "216/734, train_loss: 0.9103\n",
      "217/734, train_loss: 0.4155\n",
      "218/734, train_loss: 0.9107\n",
      "219/734, train_loss: 0.1542\n",
      "220/734, train_loss: 0.3993\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "221/734, train_loss: 1.1051\n",
      "222/734, train_loss: 0.1478\n",
      "223/734, train_loss: 0.4609\n",
      "224/734, train_loss: 0.4516\n",
      "225/734, train_loss: 0.3677\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "226/734, train_loss: 0.3906\n",
      "227/734, train_loss: 0.1740\n",
      "228/734, train_loss: 0.2157\n",
      "229/734, train_loss: 0.7528\n",
      "230/734, train_loss: 0.8420\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "231/734, train_loss: 0.5342\n",
      "232/734, train_loss: 0.3394\n",
      "233/734, train_loss: 0.1420\n",
      "234/734, train_loss: 0.1848\n",
      "235/734, train_loss: 0.5773\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "236/734, train_loss: 0.4048\n",
      "237/734, train_loss: 1.0588\n",
      "238/734, train_loss: 0.6211\n",
      "239/734, train_loss: 0.3318\n",
      "240/734, train_loss: 1.0147\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "241/734, train_loss: 1.2719\n",
      "242/734, train_loss: 0.8097\n",
      "243/734, train_loss: 0.3867\n",
      "244/734, train_loss: 0.2625\n",
      "245/734, train_loss: 0.5562\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "246/734, train_loss: 1.1602\n",
      "247/734, train_loss: 0.5188\n",
      "248/734, train_loss: 0.2482\n",
      "249/734, train_loss: 0.6393\n",
      "250/734, train_loss: 0.3940\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "251/734, train_loss: 0.7138\n",
      "252/734, train_loss: 1.6790\n",
      "253/734, train_loss: 0.3196\n",
      "254/734, train_loss: 0.2358\n",
      "255/734, train_loss: 0.3713\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "256/734, train_loss: 1.2769\n",
      "257/734, train_loss: 0.4328\n",
      "258/734, train_loss: 0.8016\n",
      "259/734, train_loss: 0.6208\n",
      "260/734, train_loss: 0.5932\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "261/734, train_loss: 0.8099\n",
      "262/734, train_loss: 0.4642\n",
      "263/734, train_loss: 0.8636\n",
      "264/734, train_loss: 0.3948\n",
      "265/734, train_loss: 1.3851\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "266/734, train_loss: 0.3066\n",
      "267/734, train_loss: 0.4153\n",
      "268/734, train_loss: 0.5299\n",
      "269/734, train_loss: 0.2698\n",
      "270/734, train_loss: 0.6970\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "271/734, train_loss: 0.3974\n",
      "272/734, train_loss: 0.7045\n",
      "273/734, train_loss: 0.1081\n",
      "274/734, train_loss: 0.4465\n",
      "275/734, train_loss: 0.4783\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "276/734, train_loss: 0.3044\n",
      "277/734, train_loss: 0.4124\n",
      "278/734, train_loss: 0.5638\n",
      "279/734, train_loss: 0.3039\n",
      "280/734, train_loss: 0.4067\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "281/734, train_loss: 0.7953\n",
      "282/734, train_loss: 0.8062\n",
      "283/734, train_loss: 0.5037\n",
      "284/734, train_loss: 1.0495\n",
      "285/734, train_loss: 0.5957\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "286/734, train_loss: 0.6216\n",
      "287/734, train_loss: 0.1588\n",
      "288/734, train_loss: 0.4423\n",
      "289/734, train_loss: 1.1137\n",
      "290/734, train_loss: 0.8977\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "291/734, train_loss: 0.2477\n",
      "292/734, train_loss: 0.1628\n",
      "293/734, train_loss: 0.5976\n",
      "294/734, train_loss: 0.5216\n",
      "295/734, train_loss: 0.9638\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "296/734, train_loss: 0.4147\n",
      "297/734, train_loss: 0.5409\n",
      "298/734, train_loss: 0.1646\n",
      "299/734, train_loss: 0.1617\n",
      "300/734, train_loss: 0.6564\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "301/734, train_loss: 0.5115\n",
      "302/734, train_loss: 0.4629\n",
      "303/734, train_loss: 0.5336\n",
      "304/734, train_loss: 0.5505\n",
      "305/734, train_loss: 0.6763\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "306/734, train_loss: 0.4281\n",
      "307/734, train_loss: 0.6476\n",
      "308/734, train_loss: 0.9507\n",
      "309/734, train_loss: 0.3194\n",
      "310/734, train_loss: 0.3286\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "311/734, train_loss: 0.5045\n",
      "312/734, train_loss: 0.3794\n",
      "313/734, train_loss: 0.3561\n",
      "314/734, train_loss: 0.4323\n",
      "315/734, train_loss: 0.5671\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "316/734, train_loss: 0.3546\n",
      "317/734, train_loss: 0.1854\n",
      "318/734, train_loss: 0.3085\n",
      "319/734, train_loss: 0.3194\n",
      "320/734, train_loss: 1.0652\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "321/734, train_loss: 0.4749\n",
      "322/734, train_loss: 0.2125\n",
      "323/734, train_loss: 1.5980\n",
      "324/734, train_loss: 0.5811\n",
      "325/734, train_loss: 0.3993\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "326/734, train_loss: 0.3701\n",
      "327/734, train_loss: 0.6875\n",
      "328/734, train_loss: 0.1279\n",
      "329/734, train_loss: 0.3124\n",
      "330/734, train_loss: 0.6389\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "331/734, train_loss: 0.2932\n",
      "332/734, train_loss: 0.6372\n",
      "333/734, train_loss: 0.3352\n",
      "334/734, train_loss: 0.2085\n",
      "335/734, train_loss: 0.4940\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "336/734, train_loss: 0.5914\n",
      "337/734, train_loss: 0.4063\n",
      "338/734, train_loss: 0.4534\n",
      "339/734, train_loss: 0.6576\n",
      "340/734, train_loss: 0.5892\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "341/734, train_loss: 0.5186\n",
      "342/734, train_loss: 1.3175\n",
      "343/734, train_loss: 0.4734\n",
      "344/734, train_loss: 0.5676\n",
      "345/734, train_loss: 0.0756\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "346/734, train_loss: 1.0926\n",
      "347/734, train_loss: 0.6771\n",
      "348/734, train_loss: 0.8739\n",
      "349/734, train_loss: 0.5299\n",
      "350/734, train_loss: 0.3902\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "351/734, train_loss: 0.7880\n",
      "352/734, train_loss: 1.2979\n",
      "353/734, train_loss: 1.0207\n",
      "354/734, train_loss: 0.4026\n",
      "355/734, train_loss: 0.4116\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "356/734, train_loss: 0.5605\n",
      "357/734, train_loss: 1.0542\n",
      "358/734, train_loss: 0.7112\n",
      "359/734, train_loss: 0.5298\n",
      "360/734, train_loss: 0.8637\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "361/734, train_loss: 0.3792\n",
      "362/734, train_loss: 0.2139\n",
      "363/734, train_loss: 0.3755\n",
      "364/734, train_loss: 0.6910\n",
      "365/734, train_loss: 0.2544\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "366/734, train_loss: 0.3635\n",
      "367/734, train_loss: 0.2037\n",
      "368/734, train_loss: 0.2740\n",
      "369/734, train_loss: 0.5884\n",
      "370/734, train_loss: 0.5679\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "371/734, train_loss: 0.1710\n",
      "372/734, train_loss: 0.6806\n",
      "373/734, train_loss: 0.7384\n",
      "374/734, train_loss: 0.5329\n",
      "375/734, train_loss: 0.3259\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "376/734, train_loss: 0.3453\n",
      "377/734, train_loss: 0.8532\n",
      "378/734, train_loss: 0.5821\n",
      "379/734, train_loss: 0.4448\n",
      "380/734, train_loss: 0.4656\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "381/734, train_loss: 0.5011\n",
      "382/734, train_loss: 0.5557\n",
      "383/734, train_loss: 0.2715\n",
      "384/734, train_loss: 0.1963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "385/734, train_loss: 0.8264\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "386/734, train_loss: 0.6782\n",
      "387/734, train_loss: 0.9273\n",
      "388/734, train_loss: 0.3986\n",
      "389/734, train_loss: 0.4380\n",
      "390/734, train_loss: 0.1812\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "391/734, train_loss: 0.3632\n",
      "392/734, train_loss: 0.4211\n",
      "393/734, train_loss: 0.4336\n",
      "394/734, train_loss: 0.1487\n",
      "395/734, train_loss: 0.7576\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "396/734, train_loss: 0.3269\n",
      "397/734, train_loss: 0.7310\n",
      "398/734, train_loss: 1.1189\n",
      "399/734, train_loss: 0.2815\n",
      "400/734, train_loss: 0.2961\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "401/734, train_loss: 0.2179\n",
      "402/734, train_loss: 0.6123\n",
      "403/734, train_loss: 0.8509\n",
      "404/734, train_loss: 0.3743\n",
      "405/734, train_loss: 0.4980\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "406/734, train_loss: 0.7589\n",
      "407/734, train_loss: 0.1804\n",
      "408/734, train_loss: 1.0296\n",
      "409/734, train_loss: 0.4389\n",
      "410/734, train_loss: 0.2465\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "411/734, train_loss: 0.1769\n",
      "412/734, train_loss: 1.1741\n",
      "413/734, train_loss: 0.5125\n",
      "414/734, train_loss: 0.4395\n",
      "415/734, train_loss: 1.0265\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "416/734, train_loss: 0.2887\n",
      "417/734, train_loss: 0.6263\n",
      "418/734, train_loss: 0.5961\n",
      "419/734, train_loss: 0.6856\n",
      "420/734, train_loss: 0.1534\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "421/734, train_loss: 0.2000\n",
      "422/734, train_loss: 0.4128\n",
      "423/734, train_loss: 0.4183\n",
      "424/734, train_loss: 0.2619\n",
      "425/734, train_loss: 1.0435\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "426/734, train_loss: 1.6173\n",
      "427/734, train_loss: 0.2104\n",
      "428/734, train_loss: 0.6514\n",
      "429/734, train_loss: 0.8882\n",
      "430/734, train_loss: 0.4720\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "431/734, train_loss: 0.6744\n",
      "432/734, train_loss: 0.1016\n",
      "433/734, train_loss: 1.3663\n",
      "434/734, train_loss: 0.4758\n",
      "435/734, train_loss: 0.8565\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "436/734, train_loss: 0.6053\n",
      "437/734, train_loss: 0.3705\n",
      "438/734, train_loss: 0.7647\n",
      "439/734, train_loss: 0.1978\n",
      "440/734, train_loss: 0.2443\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "441/734, train_loss: 0.7514\n",
      "442/734, train_loss: 0.2257\n",
      "443/734, train_loss: 0.3784\n",
      "444/734, train_loss: 0.3812\n",
      "445/734, train_loss: 0.1798\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "446/734, train_loss: 0.4354\n",
      "447/734, train_loss: 0.7124\n",
      "448/734, train_loss: 0.8726\n",
      "449/734, train_loss: 0.5549\n",
      "450/734, train_loss: 0.4285\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "451/734, train_loss: 0.4011\n",
      "452/734, train_loss: 0.3647\n",
      "453/734, train_loss: 0.3236\n",
      "454/734, train_loss: 0.8260\n",
      "455/734, train_loss: 1.2731\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "456/734, train_loss: 0.7011\n",
      "457/734, train_loss: 0.2541\n",
      "458/734, train_loss: 0.3123\n",
      "459/734, train_loss: 0.4867\n",
      "460/734, train_loss: 0.2049\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "461/734, train_loss: 0.6155\n",
      "462/734, train_loss: 0.7084\n",
      "463/734, train_loss: 0.5929\n",
      "464/734, train_loss: 1.1021\n",
      "465/734, train_loss: 0.5513\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "466/734, train_loss: 0.8772\n",
      "467/734, train_loss: 1.1654\n",
      "468/734, train_loss: 0.4228\n",
      "469/734, train_loss: 0.3905\n",
      "470/734, train_loss: 0.4586\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "471/734, train_loss: 0.3220\n",
      "472/734, train_loss: 0.8680\n",
      "473/734, train_loss: 0.1788\n",
      "474/734, train_loss: 0.1980\n",
      "475/734, train_loss: 0.7246\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "476/734, train_loss: 0.6071\n",
      "477/734, train_loss: 0.4834\n",
      "478/734, train_loss: 1.0922\n",
      "479/734, train_loss: 0.7101\n",
      "480/734, train_loss: 0.2881\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "481/734, train_loss: 0.1884\n",
      "482/734, train_loss: 0.3104\n",
      "483/734, train_loss: 0.8068\n",
      "484/734, train_loss: 0.3175\n",
      "485/734, train_loss: 0.5512\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "486/734, train_loss: 0.3572\n",
      "487/734, train_loss: 0.3128\n",
      "488/734, train_loss: 0.6038\n",
      "489/734, train_loss: 0.8014\n",
      "490/734, train_loss: 0.5642\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "491/734, train_loss: 0.3493\n",
      "492/734, train_loss: 0.3667\n",
      "493/734, train_loss: 0.4307\n",
      "494/734, train_loss: 1.0723\n",
      "495/734, train_loss: 0.9824\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "496/734, train_loss: 0.3464\n",
      "497/734, train_loss: 0.5220\n",
      "498/734, train_loss: 0.1613\n",
      "499/734, train_loss: 0.1112\n",
      "500/734, train_loss: 0.5293\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "501/734, train_loss: 0.7456\n",
      "502/734, train_loss: 0.9635\n",
      "503/734, train_loss: 0.2547\n",
      "504/734, train_loss: 0.5224\n",
      "505/734, train_loss: 0.4794\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "506/734, train_loss: 0.1433\n",
      "507/734, train_loss: 0.4697\n",
      "508/734, train_loss: 0.4746\n",
      "509/734, train_loss: 0.7046\n",
      "510/734, train_loss: 0.3351\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "511/734, train_loss: 0.3544\n",
      "512/734, train_loss: 0.4701\n",
      "513/734, train_loss: 0.6050\n",
      "514/734, train_loss: 0.1949\n",
      "515/734, train_loss: 0.3742\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "516/734, train_loss: 0.5578\n",
      "517/734, train_loss: 0.3189\n",
      "518/734, train_loss: 0.2510\n",
      "519/734, train_loss: 0.3727\n",
      "520/734, train_loss: 1.7177\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "521/734, train_loss: 0.6300\n",
      "522/734, train_loss: 0.3510\n",
      "523/734, train_loss: 0.7946\n",
      "524/734, train_loss: 0.4006\n",
      "525/734, train_loss: 0.5089\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "526/734, train_loss: 0.7613\n",
      "527/734, train_loss: 0.7712\n",
      "528/734, train_loss: 0.6340\n",
      "529/734, train_loss: 0.5860\n",
      "530/734, train_loss: 0.1937\n",
      "current epoch: 1 current accuracy: 0.6990 best accuracy: 0.6990 at epoch 1\n",
      "531/734, train_loss: 1.1070\n",
      "532/734, train_loss: 0.4265\n",
      "533/734, train_loss: 0.7222\n",
      "534/734, train_loss: 0.2280\n",
      "535/734, train_loss: 0.4969\n"
     ]
    }
   ],
   "source": [
    "# start a typical PyTorch training\n",
    "val_interval = 5\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = list()\n",
    "metric_values = list()\n",
    "writer = SummaryWriter()\n",
    "epc = 300 # Number of epoch\n",
    "for epoch in range(epc):\n",
    "    print('-' * 10)\n",
    "    print('epoch {}/{}'.format(epoch + 1, epc))\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for batch_data in train_loader:\n",
    "        step += 1\n",
    "        inputs, labels = batch_data[0].to(device), batch_data[1].to(device=device, dtype=torch.int64)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_len = len(train_ds) // train_loader.batch_size\n",
    "        print('{}/{}, train_loss: {:.4f}'.format(step, epoch_len, loss.item()))\n",
    "        writer.add_scalar('train_loss', loss.item(), epoch_len * epoch + step)\n",
    "        \n",
    "        #\n",
    "        if step % val_interval == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                num_correct = 0.\n",
    "                metric_count = 0\n",
    "                for val_data in val_loader:\n",
    "                    val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
    "                    val_outputs = model(val_images)\n",
    "                    value = torch.eq(val_outputs.argmax(dim=1), val_labels)\n",
    "                    metric_count += len(value)\n",
    "                    num_correct += value.sum().item()\n",
    "                metric = num_correct / metric_count\n",
    "                metric_values.append(metric)\n",
    "                if metric > best_metric:\n",
    "                    best_metric = metric\n",
    "                    best_metric_epoch = epoch + 1\n",
    "                    torch.save(model.state_dict(), '/home/marafath/scratch/saved_models/best_test2.pth')\n",
    "                    print('saved new best metric model')\n",
    "                print('current epoch: {} current accuracy: {:.4f} best accuracy: {:.4f} at epoch {}'.format(\n",
    "                    epoch + 1, metric, best_metric, best_metric_epoch))\n",
    "                writer.add_scalar('val_accuracy', metric, epoch + 1)\n",
    "        #\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print('epoch {} average loss: {:.4f}'.format(epoch + 1, epoch_loss))\n",
    "\n",
    "    '''\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            num_correct = 0.\n",
    "            metric_count = 0\n",
    "            for val_data in val_loader:\n",
    "                val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
    "                val_outputs = model(val_images)\n",
    "                value = torch.eq(val_outputs.argmax(dim=1), val_labels)\n",
    "                metric_count += len(value)\n",
    "                num_correct += value.sum().item()\n",
    "            metric = num_correct / metric_count\n",
    "            metric_values.append(metric)\n",
    "            #torch.save(model.state_dict(), 'model_d121_epoch_{}.pth'.format(epoch + 1))\n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), '/home/marafath/scratch/saved_models/best_metric_model_d121_test.pth')\n",
    "                print('saved new best metric model')\n",
    "            print('current epoch: {} current accuracy: {:.4f} best accuracy: {:.4f} at epoch {}'.format(\n",
    "                epoch + 1, metric, best_metric, best_metric_epoch))\n",
    "            writer.add_scalar('val_accuracy', metric, epoch + 1)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start a typical PyTorch training\n",
    "val_interval = 1\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = list()\n",
    "metric_values = list()\n",
    "writer = SummaryWriter()\n",
    "epc = 300 # Number of epoch\n",
    "for epoch in range(epc):\n",
    "    print('-' * 10)\n",
    "    print('epoch {}/{}'.format(epoch + 1, epc))\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for batch_data in train_loader:\n",
    "        step += 1\n",
    "        inputs, labels = batch_data[0].to(device), batch_data[1].to(device=device, dtype=torch.int64)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_len = len(train_ds) // train_loader.batch_size\n",
    "        print('{}/{}, train_loss: {:.4f}'.format(step, epoch_len, loss.item()))\n",
    "        writer.add_scalar('train_loss', loss.item(), epoch_len * epoch + step)\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print('epoch {} average loss: {:.4f}'.format(epoch + 1, epoch_loss))\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            num_correct = 0.\n",
    "            metric_count = 0\n",
    "            for val_data in val_loader:\n",
    "                val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
    "                val_outputs = model(val_images)\n",
    "                value = torch.eq(val_outputs.argmax(dim=1), val_labels)\n",
    "                metric_count += len(value)\n",
    "                num_correct += value.sum().item()\n",
    "            metric = num_correct / metric_count\n",
    "            metric_values.append(metric)\n",
    "            #torch.save(model.state_dict(), 'model_d121_epoch_{}.pth'.format(epoch + 1))\n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), '/home/marafath/scratch/saved_models/best_metric_model_d121_test.pth')\n",
    "                print('saved new best metric model')\n",
    "            print('current epoch: {} current accuracy: {:.4f} best accuracy: {:.4f} at epoch {}'.format(\n",
    "                epoch + 1, metric, best_metric, best_metric_epoch))\n",
    "            writer.add_scalar('val_accuracy', metric, epoch + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 0.1.0+626.g63eec3a.dirty\n",
      "Python version: 3.7.4 (default, Jul 18 2019, 19:34:02)  [GCC 5.4.0]\n",
      "Numpy version: 1.18.1\n",
      "Pytorch version: 1.5.0\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.3.0\n",
      "Nibabel version: 3.1.0\n",
      "scikit-image version: 0.14.2\n",
      "Pillow version: 7.0.0\n",
      "Tensorboard version: 2.3.0\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n",
      "Iran data: cropped and common resized, densenet+imhistnet-8bins, fold-1\n",
      "----------\n",
      "epoch 1/300\n",
      "1/734, train_loss: 0.6807\n",
      "2/734, train_loss: 40.1362\n",
      "3/734, train_loss: 95.0193\n",
      "4/734, train_loss: 30.9444\n",
      "5/734, train_loss: 177.1658\n",
      "6/734, train_loss: 66.8560\n",
      "7/734, train_loss: 113.6423\n",
      "8/734, train_loss: 51.1847\n",
      "9/734, train_loss: 0.0126\n",
      "10/734, train_loss: 50.4751\n",
      "11/734, train_loss: 39.8669\n",
      "12/734, train_loss: 56.7543\n",
      "13/734, train_loss: 0.1207\n",
      "14/734, train_loss: 0.0000\n",
      "15/734, train_loss: 92.4143\n",
      "16/734, train_loss: 12.8318\n",
      "17/734, train_loss: 2.3610\n",
      "18/734, train_loss: 43.9675\n",
      "19/734, train_loss: 0.0000\n",
      "20/734, train_loss: 118.1730\n",
      "21/734, train_loss: 0.0000\n",
      "22/734, train_loss: 92.7135\n",
      "23/734, train_loss: 0.0000\n",
      "24/734, train_loss: 0.0000\n",
      "25/734, train_loss: 27.1801\n",
      "26/734, train_loss: 27.7739\n",
      "27/734, train_loss: 19.8281\n",
      "28/734, train_loss: 0.0000\n",
      "29/734, train_loss: 10.3345\n",
      "30/734, train_loss: 21.2687\n",
      "31/734, train_loss: 9.3594\n",
      "32/734, train_loss: 33.0188\n",
      "33/734, train_loss: 0.0048\n",
      "34/734, train_loss: 0.0977\n",
      "35/734, train_loss: 6.7910\n",
      "36/734, train_loss: 23.8913\n",
      "37/734, train_loss: 6.8237\n",
      "38/734, train_loss: 14.1407\n",
      "39/734, train_loss: 3.6790\n",
      "40/734, train_loss: 3.2804\n",
      "41/734, train_loss: 12.3707\n",
      "42/734, train_loss: 19.7199\n",
      "43/734, train_loss: 0.0014\n",
      "44/734, train_loss: 4.2252\n",
      "45/734, train_loss: 4.9188\n",
      "46/734, train_loss: 1.7751\n",
      "47/734, train_loss: 0.3924\n",
      "48/734, train_loss: 1.7385\n",
      "49/734, train_loss: 2.0775\n",
      "50/734, train_loss: 0.0480\n",
      "51/734, train_loss: 0.1837\n",
      "52/734, train_loss: 5.7770\n",
      "53/734, train_loss: 1.5254\n",
      "54/734, train_loss: 8.8509\n",
      "55/734, train_loss: 0.4350\n",
      "56/734, train_loss: 0.3346\n",
      "57/734, train_loss: 0.1198\n",
      "58/734, train_loss: 8.0395\n",
      "59/734, train_loss: 3.9510\n",
      "60/734, train_loss: 2.4118\n",
      "61/734, train_loss: 3.9550\n",
      "62/734, train_loss: 4.3526\n",
      "63/734, train_loss: 14.3490\n",
      "64/734, train_loss: 6.0157\n",
      "65/734, train_loss: 0.0539\n",
      "66/734, train_loss: 3.8561\n",
      "67/734, train_loss: 0.5101\n",
      "68/734, train_loss: 0.7900\n",
      "69/734, train_loss: 1.4065\n",
      "70/734, train_loss: 1.0072\n",
      "71/734, train_loss: 1.3907\n",
      "72/734, train_loss: 6.7835\n",
      "73/734, train_loss: 5.7665\n",
      "74/734, train_loss: 5.9170\n",
      "75/734, train_loss: 9.0055\n",
      "76/734, train_loss: 1.5644\n",
      "77/734, train_loss: 6.6643\n",
      "78/734, train_loss: 4.1936\n",
      "79/734, train_loss: 1.2765\n",
      "80/734, train_loss: 2.5301\n",
      "81/734, train_loss: 1.6137\n",
      "82/734, train_loss: 0.0013\n",
      "83/734, train_loss: 0.8420\n",
      "84/734, train_loss: 4.5380\n",
      "85/734, train_loss: 0.0453\n",
      "86/734, train_loss: 0.1550\n",
      "87/734, train_loss: 8.1660\n",
      "88/734, train_loss: 5.5197\n",
      "89/734, train_loss: 2.4106\n",
      "90/734, train_loss: 5.8835\n",
      "91/734, train_loss: 10.7182\n",
      "92/734, train_loss: 0.0209\n",
      "93/734, train_loss: 22.4023\n",
      "94/734, train_loss: 3.5245\n",
      "95/734, train_loss: 11.6671\n",
      "96/734, train_loss: 0.0129\n",
      "97/734, train_loss: 0.4015\n",
      "98/734, train_loss: 0.7006\n",
      "99/734, train_loss: 0.0644\n",
      "100/734, train_loss: 5.6867\n",
      "101/734, train_loss: 1.0724\n",
      "102/734, train_loss: 1.9493\n",
      "103/734, train_loss: 0.0336\n",
      "104/734, train_loss: 10.9784\n",
      "105/734, train_loss: 0.0000\n",
      "106/734, train_loss: 0.0400\n",
      "107/734, train_loss: 7.4472\n",
      "108/734, train_loss: 4.5367\n",
      "109/734, train_loss: 3.4255\n",
      "110/734, train_loss: 4.2421\n",
      "111/734, train_loss: 0.4046\n",
      "112/734, train_loss: 1.0006\n",
      "113/734, train_loss: 0.5795\n",
      "114/734, train_loss: 2.2238\n",
      "115/734, train_loss: 9.0141\n",
      "116/734, train_loss: 0.9071\n",
      "117/734, train_loss: 2.6115\n",
      "118/734, train_loss: 1.9565\n",
      "119/734, train_loss: 0.8340\n",
      "120/734, train_loss: 2.8327\n",
      "121/734, train_loss: 0.0000\n",
      "122/734, train_loss: 1.8919\n",
      "123/734, train_loss: 0.0001\n",
      "124/734, train_loss: 0.0430\n",
      "125/734, train_loss: 10.8756\n",
      "126/734, train_loss: 0.0150\n",
      "127/734, train_loss: 0.0589\n",
      "128/734, train_loss: 1.5285\n",
      "129/734, train_loss: 9.4615\n",
      "130/734, train_loss: 18.0575\n",
      "131/734, train_loss: 16.7162\n",
      "132/734, train_loss: 0.0014\n",
      "133/734, train_loss: 15.7303\n",
      "134/734, train_loss: 8.2352\n",
      "135/734, train_loss: 5.8385\n",
      "136/734, train_loss: 4.5574\n",
      "137/734, train_loss: 0.0000\n",
      "138/734, train_loss: 18.9022\n",
      "139/734, train_loss: 24.1372\n",
      "140/734, train_loss: 15.4224\n",
      "141/734, train_loss: 5.9268\n",
      "142/734, train_loss: 3.4364\n",
      "143/734, train_loss: 9.8808\n",
      "144/734, train_loss: 2.5833\n",
      "145/734, train_loss: 0.0000\n",
      "146/734, train_loss: 11.3183\n",
      "147/734, train_loss: 14.1590\n",
      "148/734, train_loss: 0.0000\n",
      "149/734, train_loss: 36.3752\n",
      "150/734, train_loss: 11.5277\n",
      "151/734, train_loss: 25.4951\n",
      "152/734, train_loss: 31.2930\n",
      "153/734, train_loss: 3.5717\n",
      "154/734, train_loss: 0.0003\n",
      "155/734, train_loss: 4.5869\n",
      "156/734, train_loss: 0.1074\n",
      "157/734, train_loss: 15.8296\n",
      "158/734, train_loss: 0.2049\n",
      "159/734, train_loss: 28.8698\n",
      "160/734, train_loss: 0.6490\n",
      "161/734, train_loss: 0.0000\n",
      "162/734, train_loss: 0.0000\n",
      "163/734, train_loss: 0.0000\n",
      "164/734, train_loss: 10.2241\n",
      "165/734, train_loss: 0.0000\n",
      "166/734, train_loss: 21.9802\n",
      "167/734, train_loss: 4.2349\n",
      "168/734, train_loss: 0.1149\n",
      "169/734, train_loss: 0.0204\n",
      "170/734, train_loss: 9.7309\n",
      "171/734, train_loss: 6.3588\n",
      "172/734, train_loss: 8.9487\n",
      "173/734, train_loss: 23.0354\n",
      "174/734, train_loss: 5.2639\n",
      "175/734, train_loss: 12.6462\n",
      "176/734, train_loss: 1.8341\n",
      "177/734, train_loss: 14.8090\n",
      "178/734, train_loss: 0.0002\n",
      "179/734, train_loss: 34.0858\n",
      "180/734, train_loss: 1.7513\n",
      "181/734, train_loss: 0.4354\n",
      "182/734, train_loss: 3.7130\n",
      "183/734, train_loss: 1.8133\n",
      "184/734, train_loss: 1.2436\n",
      "185/734, train_loss: 2.3317\n",
      "186/734, train_loss: 26.1864\n",
      "187/734, train_loss: 0.0871\n",
      "188/734, train_loss: 10.0717\n",
      "189/734, train_loss: 0.5997\n",
      "190/734, train_loss: 13.7471\n",
      "191/734, train_loss: 13.5915\n",
      "192/734, train_loss: 13.6834\n",
      "193/734, train_loss: 0.1508\n",
      "194/734, train_loss: 0.0001\n",
      "195/734, train_loss: 11.3981\n",
      "196/734, train_loss: 0.0279\n",
      "197/734, train_loss: 0.1457\n",
      "198/734, train_loss: 1.7697\n",
      "199/734, train_loss: 0.2891\n",
      "200/734, train_loss: 1.0782\n",
      "201/734, train_loss: 15.7565\n",
      "202/734, train_loss: 1.8376\n",
      "203/734, train_loss: 0.1465\n",
      "204/734, train_loss: 17.9891\n",
      "205/734, train_loss: 17.2511\n",
      "206/734, train_loss: 6.5582\n",
      "207/734, train_loss: 11.6200\n",
      "208/734, train_loss: 11.5532\n",
      "209/734, train_loss: 30.4206\n",
      "210/734, train_loss: 6.6193\n",
      "211/734, train_loss: 11.2753\n",
      "212/734, train_loss: 4.2205\n",
      "213/734, train_loss: 0.0671\n",
      "214/734, train_loss: 0.4652\n",
      "215/734, train_loss: 0.0154\n",
      "216/734, train_loss: 7.0385\n",
      "217/734, train_loss: 9.1900\n",
      "218/734, train_loss: 0.0343\n",
      "219/734, train_loss: 6.2802\n",
      "220/734, train_loss: 3.2078\n",
      "221/734, train_loss: 0.6718\n",
      "222/734, train_loss: 1.4997\n",
      "223/734, train_loss: 14.4644\n",
      "224/734, train_loss: 7.5133\n",
      "225/734, train_loss: 3.9881\n",
      "226/734, train_loss: 0.0001\n",
      "227/734, train_loss: 0.0000\n",
      "228/734, train_loss: 0.0000\n",
      "229/734, train_loss: 0.1917\n",
      "230/734, train_loss: 31.9094\n",
      "231/734, train_loss: 0.0204\n",
      "232/734, train_loss: 25.5075\n",
      "233/734, train_loss: 2.3586\n",
      "234/734, train_loss: 63.5776\n",
      "235/734, train_loss: 104.7406\n",
      "236/734, train_loss: 67.3016\n",
      "237/734, train_loss: 3.5174\n",
      "238/734, train_loss: 0.0284\n",
      "239/734, train_loss: 3.5973\n",
      "240/734, train_loss: 5.0934\n",
      "241/734, train_loss: 0.0201\n",
      "242/734, train_loss: 23.8247\n",
      "243/734, train_loss: 0.0000\n",
      "244/734, train_loss: 0.0000\n",
      "245/734, train_loss: 10.2607\n",
      "246/734, train_loss: 130.7341\n",
      "247/734, train_loss: 54.3998\n",
      "248/734, train_loss: 5.5689\n",
      "249/734, train_loss: 0.4049\n",
      "250/734, train_loss: 0.0000\n",
      "251/734, train_loss: 71.5275\n",
      "252/734, train_loss: 129.0842\n",
      "253/734, train_loss: 124.6776\n",
      "254/734, train_loss: 0.0000\n",
      "255/734, train_loss: 0.0000\n",
      "256/734, train_loss: 0.0000\n",
      "257/734, train_loss: 0.3114\n",
      "258/734, train_loss: 6.9591\n",
      "259/734, train_loss: 40.0846\n",
      "260/734, train_loss: 0.0001\n",
      "261/734, train_loss: 0.0665\n",
      "262/734, train_loss: 12.4481\n",
      "263/734, train_loss: 0.0008\n",
      "264/734, train_loss: 1.1725\n",
      "265/734, train_loss: 28.4587\n",
      "266/734, train_loss: 2.4417\n",
      "267/734, train_loss: 0.0003\n",
      "268/734, train_loss: 1.4868\n",
      "269/734, train_loss: 5.1547\n",
      "270/734, train_loss: 55.4424\n",
      "271/734, train_loss: 0.0053\n",
      "272/734, train_loss: 11.4859\n",
      "273/734, train_loss: 4.2008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/734, train_loss: 1.7931\n",
      "275/734, train_loss: 15.9482\n",
      "276/734, train_loss: 5.8232\n",
      "277/734, train_loss: 4.0864\n",
      "278/734, train_loss: 15.8034\n",
      "279/734, train_loss: 1.4467\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f3f70a09cf20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-f3f70a09cf20>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mepoch_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ENV/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ENV/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import Callable, Sequence\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import sys\n",
    "import logging\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import monai\n",
    "from monai.data import NiftiDataset\n",
    "from monai.transforms import Compose, SpatialPad, AddChannel, ScaleIntensity, Resize, RandRotate90, RandRotate, RandZoom, ToTensor\n",
    "import os\n",
    "import math\n",
    "\n",
    "\n",
    "from monai.networks.layers.factories import Conv, Dropout, Pool, Norm\n",
    "\n",
    "\n",
    "class _DenseLayer(nn.Sequential):\n",
    "    def __init__(\n",
    "        self, spatial_dims: int, in_channels: int, growth_rate: int, bn_size: int, dropout_prob: float\n",
    "    ) -> None:\n",
    "        super(_DenseLayer, self).__init__()\n",
    "\n",
    "        out_channels = bn_size * growth_rate\n",
    "        conv_type: Callable = Conv[Conv.CONV, spatial_dims]\n",
    "        norm_type: Callable = Norm[Norm.BATCH, spatial_dims]\n",
    "        dropout_type: Callable = Dropout[Dropout.DROPOUT, spatial_dims]\n",
    "\n",
    "        self.add_module(\"norm1\", norm_type(in_channels))\n",
    "        self.add_module(\"relu1\", nn.ReLU(inplace=True))\n",
    "        self.add_module(\"conv1\", conv_type(in_channels, out_channels, kernel_size=1, bias=False))\n",
    "\n",
    "        self.add_module(\"norm2\", norm_type(out_channels))\n",
    "        self.add_module(\"relu2\", nn.ReLU(inplace=True))\n",
    "        self.add_module(\"conv2\", conv_type(out_channels, growth_rate, kernel_size=3, padding=1, bias=False))\n",
    "\n",
    "        if dropout_prob > 0:\n",
    "            self.add_module(\"dropout\", dropout_type(dropout_prob))\n",
    "\n",
    "    def forward(self, x):\n",
    "        new_features = super(_DenseLayer, self).forward(x)\n",
    "        return torch.cat([x, new_features], 1)\n",
    "\n",
    "\n",
    "class _DenseBlock(nn.Sequential):\n",
    "    def __init__(\n",
    "        self, spatial_dims: int, layers: int, in_channels: int, bn_size: int, growth_rate: int, dropout_prob: float\n",
    "    ) -> None:\n",
    "        super(_DenseBlock, self).__init__()\n",
    "        for i in range(layers):\n",
    "            layer = _DenseLayer(spatial_dims, in_channels, growth_rate, bn_size, dropout_prob)\n",
    "            in_channels += growth_rate\n",
    "            self.add_module(\"denselayer%d\" % (i + 1), layer)\n",
    "\n",
    "\n",
    "class _Transition(nn.Sequential):\n",
    "    def __init__(self, spatial_dims: int, in_channels: int, out_channels: int) -> None:\n",
    "        super(_Transition, self).__init__()\n",
    "\n",
    "        conv_type: Callable = Conv[Conv.CONV, spatial_dims]\n",
    "        norm_type: Callable = Norm[Norm.BATCH, spatial_dims]\n",
    "        pool_type: Callable = Pool[Pool.AVG, spatial_dims]\n",
    "\n",
    "        self.add_module(\"norm\", norm_type(in_channels))\n",
    "        self.add_module(\"relu\", nn.ReLU(inplace=True))\n",
    "        self.add_module(\"conv\", conv_type(in_channels, out_channels, kernel_size=1, bias=False))\n",
    "        self.add_module(\"pool\", pool_type(kernel_size=2, stride=2))\n",
    "\n",
    "\n",
    "class DenseNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Densenet based on: \"Densely Connected Convolutional Networks\" https://arxiv.org/pdf/1608.06993.pdf\n",
    "    Adapted from PyTorch Hub 2D version:\n",
    "    https://github.com/pytorch/vision/blob/master/torchvision/models/densenet.py\n",
    "\n",
    "    Args:\n",
    "        spatial_dims: number of spatial dimensions of the input image.\n",
    "        in_channels: number of the input channel.\n",
    "        out_channels: number of the output classes.\n",
    "        init_features: number of filters in the first convolution layer.\n",
    "        growth_rate: how many filters to add each layer (k in paper).\n",
    "        block_config: how many layers in each pooling block.\n",
    "        bn_size: multiplicative factor for number of bottle neck layers.\n",
    "                      (i.e. bn_size * k features in the bottleneck layer)\n",
    "        dropout_prob: dropout rate after each dense layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        spatial_dims: int,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        init_features: int = 64,\n",
    "        growth_rate: int = 32,\n",
    "        block_config: Sequence[int] = (6, 12, 24, 16),\n",
    "        bn_size: int = 4,\n",
    "        dropout_prob: float = 0.0,\n",
    "        bins=8,\n",
    "        pool_kernel=32,\n",
    "        pool_stride=32\n",
    "    ) -> None:\n",
    "\n",
    "        super(DenseNet, self).__init__()\n",
    "\n",
    "        conv_type: Callable = Conv[Conv.CONV, spatial_dims]\n",
    "        norm_type: Callable = Norm[Norm.BATCH, spatial_dims]\n",
    "        pool_type: Callable = Pool[Pool.MAX, spatial_dims]\n",
    "        avg_pool_type: Callable = Pool[Pool.ADAPTIVEAVG, spatial_dims]\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\"conv0\", conv_type(in_channels, init_features, kernel_size=7, stride=2, padding=3, bias=False)),\n",
    "                    (\"norm0\", norm_type(init_features)),\n",
    "                    (\"relu0\", nn.ReLU(inplace=True)),\n",
    "                    (\"pool0\", pool_type(kernel_size=3, stride=2, padding=1)),\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        in_channels = init_features\n",
    "        for i, num_layers in enumerate(block_config):\n",
    "            block = _DenseBlock(\n",
    "                spatial_dims=spatial_dims,\n",
    "                layers=num_layers,\n",
    "                in_channels=in_channels,\n",
    "                bn_size=bn_size,\n",
    "                growth_rate=growth_rate,\n",
    "                dropout_prob=dropout_prob,\n",
    "            )\n",
    "            self.features.add_module(\"denseblock%d\" % (i + 1), block)\n",
    "            in_channels += num_layers * growth_rate\n",
    "            if i == len(block_config) - 1:\n",
    "                self.features.add_module(\"norm5\", norm_type(in_channels))\n",
    "            else:\n",
    "                _out_channels = in_channels // 2\n",
    "                trans = _Transition(spatial_dims, in_channels=in_channels, out_channels=_out_channels)\n",
    "                self.features.add_module(\"transition%d\" % (i + 1), trans)\n",
    "                in_channels = _out_channels\n",
    "\n",
    "        # pooling and classification\n",
    "        '''\n",
    "        self.class_layers = nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\"relu\", nn.ReLU(inplace=True)),\n",
    "                    (\"norm\", avg_pool_type(1)),\n",
    "                    (\"flatten\", nn.Flatten(1)), \n",
    "                    (\"class\", nn.Linear(in_channels, out_channels)),\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        '''\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc1 = nn.Linear(1024*4*4*4, 1024)\n",
    "        self.fc2 = nn.Linear(2048, out_channels)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, conv_type):  # type: ignore\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, norm_type):  # type: ignore\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "        # 3D-ImHistNet\n",
    "        self.conv1 = nn.Conv3d(1, bins, 1, 1)\n",
    "        nn.init.constant_(self.conv1.weight, 1.0)\n",
    "        \n",
    "        \n",
    "        self.conv2 = nn.Conv3d(bins, bins, 1, 1, groups=bins)\n",
    "        nn.init.constant_(self.conv2.bias, 1.0)\n",
    "    \n",
    "        self.avgpool = nn.AvgPool3d(pool_kernel, pool_stride)\n",
    "        self.hist_fc = nn.Linear(bins*4*4*4, 1024)\n",
    "        #self.fc2 = nn.Linear(1024, no_classes)\n",
    "\n",
    "        #initialize_params(self)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.features(x)\n",
    "        x1 = torch.flatten(x1, 1)\n",
    "        x1 = self.fc1(x1)\n",
    "        \n",
    "        x2 = self.conv1(x)\n",
    "        x2 = torch.abs(x2)\n",
    "        x2 = self.conv2(x2)\n",
    "        x2 = self.relu(x2)\n",
    "        x2 = self.avgpool(x2)\n",
    "        x2 = torch.flatten(x2, 1)\n",
    "        x2 = self.hist_fc(x2)\n",
    "        \n",
    "        x_cat = torch.cat([x1, x2], 1)\n",
    "        x_cat = self.fc2(x_cat)\n",
    "        return x_cat\n",
    "\n",
    "\n",
    "def densenet121(**kwargs) -> DenseNet:\n",
    "    model = DenseNet(init_features=64, growth_rate=32, block_config=(6, 12, 24, 16), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def densenet169(**kwargs) -> DenseNet:\n",
    "    model = DenseNet(init_features=64, growth_rate=32, block_config=(6, 12, 32, 32), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def densenet201(**kwargs) -> DenseNet:\n",
    "    model = DenseNet(init_features=64, growth_rate=32, block_config=(6, 12, 48, 32), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def densenet264(**kwargs) -> DenseNet:\n",
    "    model = DenseNet(init_features=64, growth_rate=32, block_config=(6, 12, 64, 48), **kwargs)\n",
    "    return model\n",
    "\n",
    "def main():\n",
    "    monai.config.print_config()\n",
    "    logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "    print('Iran data: cropped and common resized, densenet+imhistnet-8bins, fold-1')\n",
    "\n",
    "    # Training data paths\n",
    "    data_dir = '/home/marafath/scratch/iran_organized_data2'\n",
    "    \n",
    "    #\n",
    "    covid_pat = 0\n",
    "    non_covid_pat = 0\n",
    "\n",
    "    pos_pat = []\n",
    "    neg_pat = []\n",
    "\n",
    "    for patient in os.listdir(data_dir):\n",
    "        if int(patient[-1]) == 1:\n",
    "            covid_pat += 1\n",
    "            pos_pat.append(os.path.join(data_dir,patient))\n",
    "        else:\n",
    "            non_covid_pat += 1\n",
    "            neg_pat.append(os.path.join(data_dir,patient))\n",
    "            \n",
    "    pos_val = math.floor(covid_pat/4)\n",
    "    fold = 1\n",
    "\n",
    "    for i in range(fold-1,4): # i = current fold\n",
    "        p_strt = pos_val*i + 1\n",
    "        p_end = pos_val*i + pos_val\n",
    "        n_strt = p_strt\n",
    "        n_end = p_end\n",
    "\n",
    "        pos_resample_rate = math.floor((len(neg_pat)-pos_val)/(len(pos_pat)-pos_val))\n",
    "\n",
    "        val_image = []\n",
    "        val_label = []\n",
    "        trn_image = []\n",
    "        trn_label = []\n",
    "\n",
    "        for j, pat_link in enumerate(pos_pat): \n",
    "            if j >= p_strt and j < p_end:\n",
    "                for series in os.listdir(pat_link):\n",
    "                    val_label.append(1)\n",
    "                    val_image.append(os.path.join(pat_link,series,'cropped_and_resized_image.nii.gz'))\n",
    "                    break\n",
    "            else:\n",
    "                for series in os.listdir(pat_link):\n",
    "                    for rs in range(0, pos_resample_rate):\n",
    "                        trn_label.append(1)\n",
    "                        trn_image.append(os.path.join(pat_link,series,'cropped_and_resized_image.nii.gz'))\n",
    "\n",
    "        for k, pat_link in enumerate(neg_pat): \n",
    "            if k >= n_strt and k < n_end:\n",
    "                for series in os.listdir(pat_link):\n",
    "                    val_label.append(0)\n",
    "                    val_image.append(os.path.join(pat_link,series,'cropped_and_resized_image.nii.gz'))\n",
    "                    break\n",
    "            else:\n",
    "                for series in os.listdir(pat_link):\n",
    "                    trn_label.append(0)\n",
    "                    trn_image.append(os.path.join(pat_link,series,'cropped_and_resized_image.nii.gz'))\n",
    "        break  \n",
    "\n",
    "    trn_label = np.asarray(trn_label,np.int64)\n",
    "    val_label = np.asarray(val_label,np.int64)\n",
    "\n",
    "\n",
    "    # Define transforms\n",
    "    train_transforms = Compose([\n",
    "        ScaleIntensity(),\n",
    "        AddChannel(),\n",
    "        RandRotate(range_x=10.0, range_y=10.0, range_z=10.0, prob=0.5),\n",
    "        RandZoom(min_zoom=0.9, max_zoom=1.1, prob=0.5),\n",
    "        ToTensor()\n",
    "    ])\n",
    "    \n",
    "    val_transforms = Compose([\n",
    "        ScaleIntensity(),\n",
    "        AddChannel(),\n",
    "        ToTensor()\n",
    "    ])\n",
    "\n",
    "    # create a training data loader\n",
    "    train_ds = NiftiDataset(image_files=trn_image, labels=trn_label, transform=train_transforms)\n",
    "    train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=2, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "    # create a validation data loader\n",
    "    val_ds = NiftiDataset(image_files=val_image, labels=val_label, transform=val_transforms)\n",
    "    val_loader = DataLoader(val_ds, batch_size=1, num_workers=2, pin_memory=torch.cuda.is_available())\n",
    "    \n",
    "    device = torch.device('cuda:0')\n",
    "    model = densenet121(\n",
    "        spatial_dims=3,\n",
    "        in_channels=1,\n",
    "        out_channels=2,\n",
    "    ).to(device)\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), 1e-3)\n",
    "    \n",
    "    # finetuning\n",
    "    #model.load_state_dict(torch.load('best_metric_model_d121.pth'))\n",
    "\n",
    "    # start a typical PyTorch training\n",
    "    val_interval = 1\n",
    "    best_metric = -1\n",
    "    best_metric_epoch = -1\n",
    "    epoch_loss_values = list()\n",
    "    metric_values = list()\n",
    "    writer = SummaryWriter()\n",
    "    epc = 300 # Number of epoch\n",
    "    for epoch in range(epc):\n",
    "        print('-' * 10)\n",
    "        print('epoch {}/{}'.format(epoch + 1, epc))\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        step = 0\n",
    "        for batch_data in train_loader:\n",
    "            step += 1\n",
    "            inputs, labels = batch_data[0].to(device), batch_data[1].to(device=device, dtype=torch.int64)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_len = len(train_ds) // train_loader.batch_size\n",
    "            print('{}/{}, train_loss: {:.4f}'.format(step, epoch_len, loss.item()))\n",
    "            writer.add_scalar('train_loss', loss.item(), epoch_len * epoch + step)\n",
    "        epoch_loss /= step\n",
    "        epoch_loss_values.append(epoch_loss)\n",
    "        print('epoch {} average loss: {:.4f}'.format(epoch + 1, epoch_loss))\n",
    "\n",
    "        if (epoch + 1) % val_interval == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                num_correct = 0.\n",
    "                metric_count = 0\n",
    "                for val_data in val_loader:\n",
    "                    val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
    "                    val_outputs = model(val_images)\n",
    "                    value = torch.eq(val_outputs.argmax(dim=1), val_labels)\n",
    "                    metric_count += len(value)\n",
    "                    num_correct += value.sum().item()\n",
    "                metric = num_correct / metric_count\n",
    "                metric_values.append(metric)\n",
    "                #torch.save(model.state_dict(), 'model_d121_epoch_{}.pth'.format(epoch + 1))\n",
    "                if metric > best_metric:\n",
    "                    best_metric = metric\n",
    "                    best_metric_epoch = epoch + 1\n",
    "                    torch.save(model.state_dict(), '/home/marafath/scratch/saved_models/best_model_densenet_imhistnet_f1.pth')\n",
    "                    print('saved new best metric model')\n",
    "                print('current epoch: {} current accuracy: {:.4f} best accuracy: {:.4f} at epoch {}'.format(\n",
    "                    epoch + 1, metric, best_metric, best_metric_epoch))\n",
    "                writer.add_scalar('val_accuracy', metric, epoch + 1)\n",
    "    print('train completed, best_metric: {:.4f} at epoch: {}'.format(best_metric, best_metric_epoch))\n",
    "    writer.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
